{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWWkLHBJzMCV"
      },
      "outputs": [],
      "source": [
        "#twitter API details\n",
        "import tweepy,json\n",
        "consumerKey = \"#####################\"\n",
        "consumerSecret = \"#########################\"\n",
        "accesstoken = \"##########################\"\n",
        "accesssecret = \"################################\"\n",
        "auth= tweepy.OAuthHandler(consumerKey,consumerSecret)\n",
        "auth.set_access_token(accesstoken,accesssecret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kGHVlWVzjNG"
      },
      "outputs": [],
      "source": [
        "tweet_list=[]\n",
        "class MyStreamListener(tweepy.StreamListener):\n",
        "    def __init__(self,api=None):\n",
        "        super(MyStreamListener,self).__init__()\n",
        "        self.num_tweets=0\n",
        "        self.file=open(\"data6.json\",\"w\")\n",
        "    def on_status(self,status):\n",
        "        tweet=status._json\n",
        "        self.file.write(json.dumps(tweet)+ '\\n')\n",
        "        tweet_list.append(status)\n",
        "        self.num_tweets+=1\n",
        "        if self.num_tweets<500:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "        self.file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuD1j2mjzraF"
      },
      "outputs": [],
      "source": [
        "l = MyStreamListener()\n",
        "stream =tweepy.Stream(auth,l)\n",
        "#this line filters twiiter streams to capture data by keywords\n",
        "stream.filter(track=['oil','gas','refinery','fuel','Petrol'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "HoR9kTBv0K3X",
        "outputId": "21b2ed6b-b421-44d9-a49c-b639ee20bfad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>truncated</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>user</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>contributors</th>\n",
              "      <th>retweeted_status</th>\n",
              "      <th>is_quote_status</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>entities</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>filter_level</th>\n",
              "      <th>lang</th>\n",
              "      <th>timestamp_ms</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>extended_entities</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>quoted_status_permalink</th>\n",
              "      <th>extended_tweet</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-26 18:49:14+00:00</td>\n",
              "      <td>1397625894714368007</td>\n",
              "      <td>1397625894714368000</td>\n",
              "      <td>RT @badmusib: I asked blessing to help me prep...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 938669612631298048, 'id_str': '93866961...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 18:31:32 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:49:14.590</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oil and Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-05-26 18:49:14+00:00</td>\n",
              "      <td>1397625895226064898</td>\n",
              "      <td>1397625895226064896</td>\n",
              "      <td>Oil futures finish with a modest gain, up a 4t...</td>\n",
              "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 3316713321, 'id_str': '3316713321', 'na...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:49:14.712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oil and Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-26 18:49:14+00:00</td>\n",
              "      <td>1397625896085770241</td>\n",
              "      <td>1397625896085770240</td>\n",
              "      <td>RT @Boo_Rad13y: Jet Fuel cant melt steel beams...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1208756689710616576, 'id_str': '1208756...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 14:34:24 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'hashtags': [{'text': 'MonsterHunter', 'indic...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:49:14.917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'media': [{'id': 1397560356017524737, 'id_str...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oil and Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-26 18:49:15+00:00</td>\n",
              "      <td>1397625897172168704</td>\n",
              "      <td>1397625897172168704</td>\n",
              "      <td>RT @GFuelEnergy: 🚨🇺🇸  BOGO + GIVEAWAY 🇺🇸🚨\\n\\n🤩...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1396926000278118401, 'id_str': '1396926...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 16:00:56 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'hashtags': [{'text': 'MemorialDay', 'indices...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:49:15.176</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oil and Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-26 18:49:15+00:00</td>\n",
              "      <td>1397625898719924231</td>\n",
              "      <td>1397625898719924224</td>\n",
              "      <td>RT @mindingottawa: MP @MartinBowRiver threaten...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 220833174, 'id_str': '220833174', 'name...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 12:17:19 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:49:15.545</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oil and Gas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 created_at  ...        label\n",
              "0 2021-05-26 18:49:14+00:00  ...  Oil and Gas\n",
              "1 2021-05-26 18:49:14+00:00  ...  Oil and Gas\n",
              "2 2021-05-26 18:49:14+00:00  ...  Oil and Gas\n",
              "3 2021-05-26 18:49:15+00:00  ...  Oil and Gas\n",
              "4 2021-05-26 18:49:15+00:00  ...  Oil and Gas\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df= pd.read_json('data6.json',lines=True)\n",
        "df['label'] ='Oil and Gas'\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4dCyEwo1Dxz"
      },
      "outputs": [],
      "source": [
        "df.to_csv('oil.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDvz2cdN1bNQ"
      },
      "outputs": [],
      "source": [
        "df_History = pd.read_csv('History.csv')\n",
        "df_Medical = pd.read_csv('Medical.csv')\n",
        "df_Sport = pd.read_csv('Sport.csv')\n",
        "df_Robotics = pd.read_csv('Robotics.csv')\n",
        "df_Technology =pd.read_csv('Techology.csv')\n",
        "df_oil = pd.read_csv('oil.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTo0XlD7BFZ0"
      },
      "outputs": [],
      "source": [
        "df_oil = pd.read_csv('oil.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3iQjkVL7UFU"
      },
      "outputs": [],
      "source": [
        "df_oil = df_oil[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "HIk9ljyG7c6y",
        "outputId": "4c40bcc7-ea50-4d62-9a24-b2c448b4246e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @TartarusRespawn: JUST IN: Google Strikes D...</td>\n",
              "      <td>Medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Montes19Gerardo Posteé en base a eso de hace ...</td>\n",
              "      <td>Medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @drmwarner: We have an octogenarian husband...</td>\n",
              "      <td>Medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @kmoney20205: Naughty nurse and naughty tea...</td>\n",
              "      <td>Medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @rahimshahUSA: KSA Provide Covid Vaccine at...</td>\n",
              "      <td>Medical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    label\n",
              "0  RT @TartarusRespawn: JUST IN: Google Strikes D...  Medical\n",
              "1  @Montes19Gerardo Posteé en base a eso de hace ...  Medical\n",
              "2  RT @drmwarner: We have an octogenarian husband...  Medical\n",
              "3  RT @kmoney20205: Naughty nurse and naughty tea...  Medical\n",
              "4  RT @rahimshahUSA: KSA Provide Covid Vaccine at...  Medical"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_Medical = df_Medical[['text','label']]\n",
        "df_Medical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHGBeCnS7iyl"
      },
      "outputs": [],
      "source": [
        "df_Sport = df_Sport[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xpK-T5T7nBY"
      },
      "outputs": [],
      "source": [
        "df_data = df_data[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RolbhLfR7p1z"
      },
      "outputs": [],
      "source": [
        "df_Robotics = df_Robotics[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDbEqwxv-o0E"
      },
      "outputs": [],
      "source": [
        "df_Technology = df_Technology[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgmtDp7t-wtC"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([df_Histo1,df_oil])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3X0h1FR_r91",
        "outputId": "fa021812-ea47-447b-ee0d-ee9a125c7f86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2113, 38)"
            ]
          },
          "execution_count": 65,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UtXwTDS_1Nn"
      },
      "outputs": [],
      "source": [
        "data.to_csv('Train_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p_BvnKvMtxk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('Train_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "nBhdDAMSATrH",
        "outputId": "1cba7b00-feda-4fd7-d14f-7a7f1669db4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>truncated</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>user</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>contributors</th>\n",
              "      <th>retweeted_status</th>\n",
              "      <th>is_quote_status</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>entities</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>filter_level</th>\n",
              "      <th>lang</th>\n",
              "      <th>timestamp_ms</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>quoted_status_permalink</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>extended_tweet</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>extended_entities</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021-05-26 18:09:23+00:00</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>RT @ColumbiaRecords: “BUTTER” by BTS has offic...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'id': 771919061244604416, 'id_str': '77191906...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Sun May 23 05:26:20 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:09:23.745</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-05-26 18:09:24+00:00</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>RT @chartdata: .@ArianaGrande has now surpasse...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'id': 1264263560298762240, 'id_str': '1264263...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 18:08:02 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:09:24.321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2021-05-26 18:09:24+00:00</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>@FOX10Phoenix @azfamily @abc15</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18999261.0</td>\n",
              "      <td>18999261.0</td>\n",
              "      <td>FOX10Phoenix</td>\n",
              "      <td>{'id': 36101474, 'id_str': '36101474', 'name':...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>und</td>\n",
              "      <td>2021-05-26 18:09:24.317</td>\n",
              "      <td>1.395444e+18</td>\n",
              "      <td>1.395444e+18</td>\n",
              "      <td>{'created_at': 'Thu May 20 18:18:59 +0000 2021...</td>\n",
              "      <td>{'url': 'https://t.co/M6JWMOAtYy', 'expanded':...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2021-05-26 18:09:24+00:00</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>RT @marcorubio: Knew host for SARS in 4 months...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'id': 1027190315742945281, 'id_str': '1027190...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed May 26 17:36:30 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>en</td>\n",
              "      <td>2021-05-26 18:09:24.349</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2021-05-26 18:09:24+00:00</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>1.397616e+18</td>\n",
              "      <td>Diesen wirklich bemerkenswerten Roman von @pas...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'id': 37639653, 'id_str': '37639653', 'name':...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'id': 'b9b77321807927e1', 'url': 'https://api...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>low</td>\n",
              "      <td>de</td>\n",
              "      <td>2021-05-26 18:09:24.315</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0, 140]</td>\n",
              "      <td>{'full_text': 'Diesen wirklich bemerkenswerten...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... extended_entities    label\n",
              "0           0           0.0  ...               NaN  History\n",
              "1           1           1.0  ...               NaN  History\n",
              "2           2           2.0  ...               NaN  History\n",
              "3           3           3.0  ...               NaN  History\n",
              "4           4           4.0  ...               NaN  History\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is2q6PpXBb8Y"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCozRCoQBrz6",
        "outputId": "99171c88-c3ea-49f4-f4cf-6873f550c76a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2113, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[['id','text','label']]\n",
        "data.head()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DQ3oK3lCGrx",
        "outputId": "63f9546f-685d-4dc2-fcd6-8c3a8e27c64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/11/4d/378ab91284c2c3a06ab475b287721c09b7951d5ecb3edf4ffb0e1e7a568a/contractions-0.0.49-py2.py3-none-any.whl\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
            "Collecting anyascii\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 6.7MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 25.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85392 sha256=25e3c773e9c19e0e604c500465ede928da321078c2c5a12569a1649b1227d2d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: anyascii, pyahocorasick, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.49 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-1.2.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "%matplotlib inline\n",
        "!pip install emoji\n",
        "import emoji\n",
        "import re\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "#words = set(nltk.corpus.words.words())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTJInfsf9hF_"
      },
      "outputs": [],
      "source": [
        "#cleaning and preprocessing of the data\n",
        "def remove_contraction(tweet):\n",
        "    contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"'cause\": \"because\",\n",
        "                           \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                           \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\",\n",
        "                           \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\",\n",
        "                           \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n",
        "                           \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\",\n",
        "                           \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
        "                           \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\",\n",
        "                           \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\",\n",
        "                           \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
        "                           \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                           \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
        "                           \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
        "                           \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
        "                           \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                           \"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n",
        "                           \"that's\": \"that is\",\n",
        "                           \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\",\n",
        "                           \"here's\": \"here is\",\n",
        "                           \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
        "                           \"they'll've\": \"they will have\",\n",
        "                           \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                           \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\",\n",
        "                           \"we'll've\": \"we will have\",\n",
        "                           \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
        "                           \"what'll've\": \"what will have\",\n",
        "                           \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
        "                           \"when've\": \"when have\",\n",
        "                           \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n",
        "                           \"who'll\": \"who will\",\n",
        "                           \"who'll've\": \"who will have\",\n",
        "                           \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\",\n",
        "                           \"will've\": \"will have\",\n",
        "                           \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "                           \"wouldn't\": \"would not\",\n",
        "                           \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                           \"y'all'd've\": \"you all would have\",\n",
        "                           \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\",\n",
        "                           \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
        "                           \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
        "    for s in specials:\n",
        "        tweet = tweet.replace(s, \"'\")\n",
        "    tweet = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in tweet.split(\" \")])\n",
        "    return tweet\n",
        "\n",
        "def clean_repeat_patterns_lower(tweet,remove_repeat_text=True, remove_patterns_text=True, is_lower=True):\n",
        "\n",
        "    RE_PATTERNS = {\n",
        "    ' american ':\n",
        "        [\n",
        "            'amerikan'\n",
        "        ],\n",
        "\n",
        "    ' adolf ':\n",
        "        [\n",
        "            'adolf'\n",
        "        ],\n",
        "\n",
        "\n",
        "    ' hitler ':\n",
        "        [\n",
        "            'hitler'\n",
        "        ],\n",
        "\n",
        "    ' fuck':\n",
        "        [\n",
        "            '(f)(u|[^a-z0-9 ])(c|[^a-z0-9 ])(k|[^a-z0-9 ])([^ ])*',\n",
        "            '(f)([^a-z]*)(u)([^a-z]*)(c)([^a-z]*)(k)',\n",
        "            ' f[!@#\\$%\\^\\&\\*]*u[!@#\\$%\\^&\\*]*k', 'f u u c',\n",
        "            '(f)(c|[^a-z ])(u|[^a-z ])(k)', r'f\\*',\n",
        "            'feck ', ' fux ', 'f\\*\\*', 'f**k','fu*k',\n",
        "            'f\\-ing', 'f\\.u\\.', 'f###', ' fu ', 'f@ck', 'f u c k', 'f uck', 'f ck'\n",
        "        ],\n",
        "\n",
        "    ' ass ':\n",
        "        [\n",
        "            '[^a-z]ass ', '[^a-z]azz ', 'arrse', ' arse ', '@\\$\\$',\n",
        "            '[^a-z]anus', ' a\\*s\\*s', '[^a-z]ass[^a-z ]',\n",
        "            'a[@#\\$%\\^&\\*][@#\\$%\\^&\\*]', '[^a-z]anal ', 'a s s','a55', '@$$'\n",
        "        ],\n",
        "\n",
        "    ' ass hole ':\n",
        "        [\n",
        "            ' a[s|z]*wipe', 'a[s|z]*[w]*h[o|0]+[l]*e', '@\\$\\$hole', 'a**hole'\n",
        "        ],\n",
        "\n",
        "    ' bitch ':\n",
        "        [\n",
        "            'b[w]*i[t]*ch', 'b!tch',\n",
        "            'bi\\+ch', 'b!\\+ch', '(b)([^a-z]*)(i)([^a-z]*)(t)([^a-z]*)(c)([^a-z]*)(h)',\n",
        "            'biatch', 'bi\\*\\*h', 'bytch', 'b i t c h', 'b!tch', 'bi+ch', 'l3itch'\n",
        "        ],\n",
        "\n",
        "    ' bastard ':\n",
        "        [\n",
        "            'ba[s|z]+t[e|a]+rd'\n",
        "        ],\n",
        "\n",
        "    ' trans gender':\n",
        "        [\n",
        "            'transgender'\n",
        "        ],\n",
        "\n",
        "    ' gay ':\n",
        "        [\n",
        "            'gay'\n",
        "        ],\n",
        "\n",
        "    ' cock ':\n",
        "        [\n",
        "            '[^a-z]cock', 'c0ck', '[^a-z]cok ', 'c0k', '[^a-z]cok[^aeiou]', ' cawk',\n",
        "            '(c)([^a-z ])(o)([^a-z ]*)(c)([^a-z ]*)(k)', 'c o c k'\n",
        "        ],\n",
        "\n",
        "    ' dick ':\n",
        "        [\n",
        "            ' dick[^aeiou]', 'deek', 'd i c k', 'dik'\n",
        "        ],\n",
        "\n",
        "    ' suck ':\n",
        "        [\n",
        "            'sucker', '(s)([^a-z ]*)(u)([^a-z ]*)(c)([^a-z ]*)(k)', 'sucks', '5uck', 's u c k'\n",
        "        ],\n",
        "\n",
        "    ' cunt ':\n",
        "        [\n",
        "            'cunt', 'c u n t'\n",
        "        ],\n",
        "\n",
        "    ' bull shit ':\n",
        "        [\n",
        "            'bullsh\\*t', 'bull\\$hit'\n",
        "        ],\n",
        "\n",
        "    ' homo sex ual':\n",
        "        [\n",
        "            'homosexual'\n",
        "        ],\n",
        "\n",
        "    ' jerk ':\n",
        "        [\n",
        "            'jerk'\n",
        "        ],\n",
        "\n",
        "    ' idiot ':\n",
        "        [\n",
        "            'i[d]+io[t]+', '(i)([^a-z ]*)(d)([^a-z ]*)(i)([^a-z ]*)(o)([^a-z ]*)(t)', 'idiots'\n",
        "                                                                                      'i d i o t'\n",
        "        ],\n",
        "\n",
        "    ' dumb ':\n",
        "        [\n",
        "            '(d)([^a-z ]*)(u)([^a-z ]*)(m)([^a-z ]*)(b)'\n",
        "        ],\n",
        "\n",
        "    ' shit ':\n",
        "        [\n",
        "            'shitty', '(s)([^a-z ]*)(h)([^a-z ]*)(i)([^a-z ]*)(t)', 'shite', '\\$hit', 's h i t', '$h1t'\n",
        "        ],\n",
        "\n",
        "    ' shit hole ':\n",
        "        [\n",
        "            'shythole'\n",
        "        ],\n",
        "\n",
        "    ' retard ':\n",
        "        [\n",
        "            'returd', 'retad', 'retard', 'wiktard', 'wikitud'\n",
        "        ],\n",
        "\n",
        "    ' rape ':\n",
        "        [\n",
        "            ' raped'\n",
        "        ],\n",
        "\n",
        "    ' dumb ass':\n",
        "        [\n",
        "            'dumbass', 'dubass'\n",
        "        ],\n",
        "\n",
        "    ' ass head':\n",
        "        [\n",
        "            'butthead'\n",
        "        ],\n",
        "\n",
        "    ' sex ':\n",
        "        [\n",
        "            'sexy', 's3x', 'sexuality'\n",
        "        ],\n",
        "\n",
        "\n",
        "    ' nigger ':\n",
        "        [\n",
        "            'nigger', 'ni[g]+a', ' nigr ', 'negrito', 'niguh', 'n3gr', 'n i g g e r'\n",
        "        ],\n",
        "\n",
        "    ' shut the fuck up':\n",
        "        [\n",
        "            'stfu', 'st*u'\n",
        "        ],\n",
        "\n",
        "    ' pussy ':\n",
        "        [\n",
        "            'pussy[^c]', 'pusy', 'pussi[^l]', 'pusses', 'p*ssy'\n",
        "        ],\n",
        "\n",
        "    ' faggot ':\n",
        "        [\n",
        "            'faggot', ' fa[g]+[s]*[^a-z ]', 'fagot', 'f a g g o t', 'faggit',\n",
        "            '(f)([^a-z ]*)(a)([^a-z ]*)([g]+)([^a-z ]*)(o)([^a-z ]*)(t)', 'fau[g]+ot', 'fae[g]+ot',\n",
        "        ],\n",
        "\n",
        "    ' mother fucker':\n",
        "        [\n",
        "            ' motha ', ' motha f', ' mother f', 'motherucker',\n",
        "        ],\n",
        "\n",
        "    ' whore ':\n",
        "        [\n",
        "            'wh\\*\\*\\*', 'w h o r e'\n",
        "        ],\n",
        "    ' fucking ':\n",
        "        [\n",
        "            'f*$%-ing'\n",
        "        ],\n",
        "}\n",
        "\n",
        "    if is_lower:\n",
        "      tweet=tweet.lower()\n",
        "\n",
        "    if remove_patterns_text:\n",
        "      for target, patterns in RE_PATTERNS.items():\n",
        "        for pat in patterns:\n",
        "          tweet=str(tweet).replace(pat, target)\n",
        "\n",
        "    if remove_repeat_text:\n",
        "     tweet = re.sub(r'(.)\\1{2,}', r'\\1', tweet)\n",
        "\n",
        "     tweet = str(tweet).replace(\"\\n\", \" \")\n",
        "     tweet = re.sub(r'[^\\w\\s]',' ',tweet)\n",
        "     tweet = re.sub('[0-9]',\"\",tweet)\n",
        "     tweet = re.sub(\" +\", \" \", tweet)\n",
        "     tweet = re.sub(\"([^\\x00-\\x7F])+\",\" \",tweet)\n",
        "     tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "     tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "     shortword= re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
        "     tweet = shortword.sub('', tweet)\n",
        "     tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "         if w.lower() in words or not w.isalpha())\n",
        "     return tweet\n",
        "\n",
        "\n",
        "\n",
        "def remove_emojis(tweet):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        u\"\\U0001F1F2-\\U0001F1F4\"\n",
        "        u\"\\U0001F1E6-\\U0001F1FF\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U0001F1F2\"\n",
        "        u\"\\U0001F1F4\"\n",
        "        u\"\\U0001F620\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', tweet)\n",
        "\n",
        "def prepare_stopwords_list():\n",
        "    stopword_list=STOP_WORDS\n",
        "    potential_stopwords=['editor', 'reference', 'thank', 'work','find', 'good', 'know', 'like', 'look', 'thing', 'want', 'time', 'list', 'section','wikipedia', 'doe', 'add','new', 'try', 'think', 'write','use', 'user', 'way', 'page']\n",
        "    for word in potential_stopwords:\n",
        "        stopword_list.add(word)\n",
        "    return(stopword_list)\n",
        "\n",
        "def remove_stop_words(tweet, remove_stop=True):\n",
        "    stop_words=prepare_stopwords_list()\n",
        "    output = \"\"\n",
        "    if remove_stop:\n",
        "      tweet=tweet.split(\" \")\n",
        "      for word in tweet:\n",
        "        if word not in stop_words:\n",
        "          output=output + \" \" + word\n",
        "    else :\n",
        "      output=text\n",
        "    return str(output.strip())\n",
        "\n",
        "def lemmatize(tweet, lemmatization=True):\n",
        "  wordnet_lemmatizer = WordNetLemmatizer()\n",
        "  output=\"\"\n",
        "  if lemmatization:\n",
        "    tweet=tweet.split(\" \")\n",
        "    for word in tweet:\n",
        "       word1 = wordnet_lemmatizer.lemmatize(word, pos = \"n\")\n",
        "       word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "       word3 = wordnet_lemmatizer.lemmatize(word2, pos = \"a\")\n",
        "       word4 = wordnet_lemmatizer.lemmatize(word3, pos = \"r\")\n",
        "       output=output + \" \" + word4\n",
        "  else:\n",
        "    output=tweet\n",
        "  return str(output.strip())\n",
        "\n",
        "def clean_text_column(text_column):\n",
        "    return text_column.apply(lambda x: clean_text(x))\n",
        "\n",
        "def clean_text(tweet):\n",
        "    tweet=remove_contraction(tweet)\n",
        "    tweet=clean_repeat_patterns_lower(tweet)\n",
        "    tweet=remove_emojis(tweet)\n",
        "    tweet=remove_stop_words(tweet)\n",
        "    tweet=lemmatize(tweet)\n",
        "    return tweet\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEyoRNgcDl8W"
      },
      "outputs": [],
      "source": [
        "data['tweet'] = data['text'].map(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Ytbjp7SmDsue",
        "outputId": "908b3cb3-0879-4359-b909-68c4e8e9287c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                          tweet\n",
              "0           NaN  ...                               \n",
              "1  1.397615e+18  ...  believe work love sooner late\n",
              "2           NaN  ...                               \n",
              "3           NaN  ...                tvg_infantil_xa\n",
              "4           NaN  ...             nova scotia insane\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "bgwDDXkRDvvs",
        "outputId": "22c9d142-1582-4801-9cd9-aae5161172a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                            tokenized\n",
              "0           NaN  ...                                   []\n",
              "1  1.397615e+18  ...  [believe, work, love, sooner, late]\n",
              "2           NaN  ...                                   []\n",
              "3           NaN  ...                    [tvg_infantil_xa]\n",
              "4           NaN  ...               [nova, scotia, insane]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['tokenized'] = data['tweet'].apply(word_tokenize)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "buzKyrbVEHp0",
        "outputId": "a7617b47-7388-4fdc-9426-7c7b8507a8b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>[(believe, JJ), (work, NN), (love, VBD), (soon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>[(tvg_infantil_xa, NN)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>[(nova, JJ), (scotia, NN), (insane, NN)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                           pos_tags\n",
              "0           NaN  ...                                                 []\n",
              "1  1.397615e+18  ...  [(believe, JJ), (work, NN), (love, VBD), (soon...\n",
              "2           NaN  ...                                                 []\n",
              "3           NaN  ...                            [(tvg_infantil_xa, NN)]\n",
              "4           NaN  ...           [(nova, JJ), (scotia, NN), (insane, NN)]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['pos_tags'] = data['tokenized'].apply(nltk.tag.pos_tag)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb7nWD8yEZCc"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "G_ZKM9E3EqkM",
        "outputId": "8ebfe8b3-e428-4c1e-cf6b-87aff0f3395e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>[(believe, JJ), (work, NN), (love, VBD), (soon...</td>\n",
              "      <td>[(believe, a), (work, n), (love, v), (sooner, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>[(tvg_infantil_xa, NN)]</td>\n",
              "      <td>[(tvg_infantil_xa, n)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>[(nova, JJ), (scotia, NN), (insane, NN)]</td>\n",
              "      <td>[(nova, a), (scotia, n), (insane, n)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                        wordnet_pos\n",
              "0           NaN  ...                                                 []\n",
              "1  1.397615e+18  ...  [(believe, a), (work, n), (love, v), (sooner, ...\n",
              "2           NaN  ...                                                 []\n",
              "3           NaN  ...                             [(tvg_infantil_xa, n)]\n",
              "4           NaN  ...              [(nova, a), (scotia, n), (insane, n)]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['wordnet_pos'] = data['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "wEcKMzfXEttF",
        "outputId": "7762c2e8-3853-46d2-bdae-80a3d663af8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>[(believe, JJ), (work, NN), (love, VBD), (soon...</td>\n",
              "      <td>[(believe, a), (work, n), (love, v), (sooner, ...</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>[(tvg_infantil_xa, NN)]</td>\n",
              "      <td>[(tvg_infantil_xa, n)]</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>[(nova, JJ), (scotia, NN), (insane, NN)]</td>\n",
              "      <td>[(nova, a), (scotia, n), (insane, n)]</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                           lemmatized\n",
              "0           NaN  ...                                   []\n",
              "1  1.397615e+18  ...  [believe, work, love, sooner, late]\n",
              "2           NaN  ...                                   []\n",
              "3           NaN  ...                    [tvg_infantil_xa]\n",
              "4           NaN  ...               [nova, scotia, insane]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "data['lemmatized'] = data['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "CrcgVSZPEz5s",
        "outputId": "271c9987-6dbf-4094-bfb9-a349fdf9ffb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>lemma_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>Medical</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>[(believe, JJ), (work, NN), (love, VBD), (soon...</td>\n",
              "      <td>[(believe, a), (work, n), (love, v), (sooner, ...</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>Oil and Gas</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>[(tvg_infantil_xa, NN)]</td>\n",
              "      <td>[(tvg_infantil_xa, n)]</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>Medical</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>[(nova, JJ), (scotia, NN), (insane, NN)]</td>\n",
              "      <td>[(nova, a), (scotia, n), (insane, n)]</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>nova scotia insane</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                      lemma_str\n",
              "0           NaN  ...                               \n",
              "1  1.397615e+18  ...  believe work love sooner late\n",
              "2           NaN  ...                               \n",
              "3           NaN  ...                tvg_infantil_xa\n",
              "4           NaN  ...             nova scotia insane\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['lemma_str'] = [' '.join(map(str,l)) for l in data['lemmatized']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxpy3v4II6v7",
        "outputId": "2d3a66b0-1314-45da-f880-161fedd2f78c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Oil and Gas    500\n",
              "Medical        500\n",
              "Sport          498\n",
              "History        416\n",
              "Robotics       175\n",
              "Technology      24\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qww6iySUHDHc"
      },
      "outputs": [],
      "source": [
        "cleanup_nums = {\"label\":{\"Robotics\": 0, \"Medical\": 1,'Oil and Gas':2,'Sport':3,'History':4,'Technology':5}}\n",
        "\n",
        "\n",
        "#\"Robotics\": 0, \"Medical\": 1,'Oil and Gas':2,'Sport':3,'History':4,'Technology':5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "BAJuvvdhJRDb",
        "outputId": "71cdd1ec-d302-4369-cc11-15150329d2bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>lemma_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Unless it means abolishing the filibster.</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.397615e+18</td>\n",
              "      <td>@launchzoneann Just keep believing and keep wo...</td>\n",
              "      <td>5</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>[(believe, JJ), (work, NN), (love, VBD), (soon...</td>\n",
              "      <td>[(believe, a), (work, n), (love, v), (sooner, ...</td>\n",
              "      <td>[believe, work, love, sooner, late]</td>\n",
              "      <td>believe work love sooner late</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Los héroes si exiten y no son esos de camuflaj...</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@tvg_infantil_xa As grandes tecnolóxicas tende...</td>\n",
              "      <td>2</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>[(tvg_infantil_xa, NN)]</td>\n",
              "      <td>[(tvg_infantil_xa, n)]</td>\n",
              "      <td>[tvg_infantil_xa]</td>\n",
              "      <td>tvg_infantil_xa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Nova Scotia: Ya'll are fucking insane.</td>\n",
              "      <td>1</td>\n",
              "      <td>nova scotia insane</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>[(nova, JJ), (scotia, NN), (insane, NN)]</td>\n",
              "      <td>[(nova, a), (scotia, n), (insane, n)]</td>\n",
              "      <td>[nova, scotia, insane]</td>\n",
              "      <td>nova scotia insane</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                      lemma_str\n",
              "0           NaN  ...                               \n",
              "1  1.397615e+18  ...  believe work love sooner late\n",
              "2           NaN  ...                               \n",
              "3           NaN  ...                tvg_infantil_xa\n",
              "4           NaN  ...             nova scotia insane\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.replace(cleanup_nums)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnFNzuAHJZ86"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg1ypvpiJzZ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "Train_X = None\n",
        "Train_Y = None\n",
        "Test_X = None\n",
        "Test_Y = None\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(data['lemma_str'],data['label'],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUHsW3Y4J8Nn"
      },
      "outputs": [],
      "source": [
        "Encoder=None\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nQgSY2UKBnz",
        "outputId": "5d56ab53-6bc1-43e9-98f0-5857e7199c70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2113, 2853)"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect=None\n",
        "count_vect = CountVectorizer(lowercase=False)\n",
        "X_train_counts = count_vect.fit_transform(data['lemma_str'].tolist())\n",
        "X_train_counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LRb83PHKF7h"
      },
      "outputs": [],
      "source": [
        "Tfidf_vect=None\n",
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(data['lemma_str'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Iv7ixrCKPL5",
        "outputId": "c1e3208c-de21-4292-f532-a6dfce48fe17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'believe': 256, 'work': 2827, 'love': 1535, 'sooner': 2377, 'late': 1462, 'tvg_infantil_xa': 2673, 'nova': 1759, 'scotia': 2249, 'insane': 1331, 'wish': 2821, 'endless': 862, 'happiness': 1184, 'health': 1201, 'know': 1443, 'random': 2065, 'exclusive': 921, 'tell': 2542, 'grapefruit': 1150, 'lavender': 1466, 'essential': 896, 'create': 614, 'wonderful': 2825, 'scent': 2237, 'succulent': 2478, 'citrus': 471, 'body': 300, 'monique_c': 1676, 'igor_larionovii': 1272, 'excellent': 917, 'people': 1858, 'right': 2172, 'forget': 1049, 'crash': 612, 'price': 1972, 'nearly': 1733, 'marriage': 1589, 'candidate': 385, 'doctor': 779, 'ready': 2077, 'heart': 1204, 'care': 398, 'slugger': 2353, 'hybrid': 1258, 'scandium': 2232, 'softball': 2366, 'sport': 2401, 'second': 2259, 'chance': 434, 'league': 1473, 'false': 967, 'start': 2422, 'arm': 154, 'superior': 2489, 'ship': 2303, 'navigation': 1729, 'sail': 2211, 'world': 2831, 'fake': 963, 'news': 1742, 'data': 655, 'validation': 2734, 'machine': 1548, 'learn': 1475, 'imperative': 1283, 'optional': 1794, 'analytics': 111, 'diversity': 777, 'race': 2051, 'inclusion': 1298, 'julisco_': 1410, 'white': 2806, 'course': 604, 'mate': 1605, 'firm': 1016, 'leonaldo__': 1486, 'pour': 1948, 'plus': 1910, 'grand': 1147, 'hunt': 1255, 'shoot': 2306, 'theoretically': 2566, 'open': 1788, 'reasonable': 2083, 'see': 2265, 'leprechaun': 1487, 'go': 1128, 'deflationary': 692, 'token': 2597, 'burn': 357, 'best': 264, 'grad': 1143, 'house': 1250, 'gallop': 1088, 'icon': 1262, 'honestly': 1235, 'conversation': 579, 'week': 2796, 'hospital': 1246, 'bill': 272, 'away': 204, 'homelessness': 1231, 'friend': 1071, 'instead': 1343, 'saman': 2218, 'yang': 2840, 'volunteer': 2769, 'community': 534, 'service': 2277, 'jim_jordan': 1396, 'steel': 2432, 'lumber': 1540, 'poultry': 1947, 'beef': 250, 'fruit': 1072, 'investor_': 1374, 'mean': 1613, 'privacy': 1984, 'heritage': 1214, 'history': 1225, 'urgent': 2721, 'need': 1736, 'group': 1165, 'blood': 294, 'ruby': 2197, 'listen': 1516, 'add': 43, 'station': 2426, 'air': 74, 'link': 1513, 'activist': 34, 'investor': 1373, 'historic': 1224, 'climate': 486, 'campaign': 378, 'important': 1287, 'performance': 1861, 'total': 2612, 'decision': 675, 'suspend': 2508, 'cash': 405, 'distribution': 771, 'transportation': 2638, 'company': 536, 'limit': 1507, 'share': 2292, 'female': 992, 'formula': 1053, 'driver': 811, 'pitchfork': 1892, 'combine': 518, 'garage': 1092, 'rock': 2182, 'post': 1940, 'punk': 2028, 'revival': 2168, 'dance': 652, 'today': 2596, 'national': 1723, 'director': 754, 'collins': 510, 'speak': 2387, 'therapeutic': 2569, 'potential': 1944, 'billion': 273, 'lead': 1469, 'artist': 163, 'model': 1670, 'tsar': 2667, 'coronate': 586, 'russia': 2203, 'force': 1046, 'abdicate': 12, 'march': 1581, 'forever': 1048, 'pack': 1818, 'thats': 2560, 'team': 2532, 'vital': 2764, 'game': 1089, 'industry': 1312, 'safe': 2209, 'turn': 2672, 'hard': 1187, 'question': 2046, 'presence': 1962, 'make': 1560, 'black': 285, 'woman': 2823, 'stand': 2418, 'podium': 1915, 'wonder': 2824, 'big': 268, 'sure': 2497, 'meet': 1619, 'monster': 1679, 'raise': 2061, 'money': 1675, 'circuit': 468, 'incredible': 1303, 'shell': 2298, 'case': 404, 'precedent': 1955, 'area': 151, 'district': 772, 'board': 298, 'june': 1412, 'reject': 2114, 'vote': 2770, 'slash': 2344, 'pollution': 1924, 'weekly': 2798, 'mensal': 1626, 'petrol': 1872, 'artificial': 162, 'intelligence': 1352, 'powerful': 1950, 'tool': 2605, 'take': 2521, 'level': 1490, 'teach': 2529, 'funny': 1078, 'understand': 2689, 'respond': 2156, 'west': 2802, 'tournant': 2616, 'utdleon_': 2726, 'dragon': 803, 'transfer': 2633, 'strike': 2455, 'deal': 666, 'finish': 1013, 'refinery': 2100, 'concept': 547, 'amaze': 100, 'design': 719, 'jen_schro': 1390, 'ou_softbal': 1805, 'check': 447, 'shine': 2302, 'spin': 2396, 'reinstall': 2113, 'twitter': 2677, 'orang': 1797, 'giant': 1118, 'killer': 1434, 'cusp': 642, 'build': 353, 'massive': 1602, 'crude': 630, 'pipeline': 1890, 'day': 659, 'great': 1154, 'couple': 602, 'crisis': 621, 'month': 1681, 'seed': 2266, 'merely': 1630, 'exactly': 910, 'depression': 715, 'anxiety': 130, 'past': 1843, 'oxygen': 1815, 'support': 2492, 'medical': 1616, 'college': 509, 'fifth': 999, 'previous': 1971, 'tear': 2533, 'bring': 335, 'mystery': 1713, 'flavor': 1024, 'bogo': 301, 'pull': 2026, 'feel': 987, 'gaslight': 1095, 'butter': 367, 'music': 1709, 'video': 2750, 'break': 328, 'gasoline': 1096, 'riot': 2174, 'ethnic': 902, 'cleanse': 482, 'hopefully': 1242, 'celebrate': 415, 'dodgy': 782, 'encourager': 860, 'usage': 2723, 'application': 142, 'signal': 2319, 'scanner': 2233, 'yesterday': 2844, 'minister': 1652, 'energy': 864, 'say': 2227, 'environmental': 880, 'fund': 1077, 'interest': 1359, 'live': 1520, 'fuel': 1074, 'exams_online_pu': 915, 'flap': 1023, 'happy': 1185, 'substitute': 2474, 'find': 1011, 'outside': 1808, 'allure_magazine': 92, 'catch': 410, 'digital': 747, 'cover': 607, 'star': 2421, 'way': 2788, 'present': 1963, 'control': 578, 'valid': 2733, 'surpass': 2502, 'para': 1832, 'fight': 1001, 'violence': 2756, 'mental': 1627, 'celebration': 416, 'morning': 1687, 'student': 2462, 'social': 2361, 'galaxy': 1085, 'fold': 1032, 'display': 764, 'camera': 376, 'octogenarian': 1776, 'husband': 1256, 'wife': 2810, 'acquire': 30, 'covid': 609, 'story': 2443, 'la_starlight': 1448, 'kalala__': 1419, 'duel': 817, 'khalsa_iyer': 1430, 'remember': 2126, 'fact': 955, 'birth': 279, 'saint': 2212, 'author': 191, 'military': 1648, 'fiction': 995, 'visit': 2762, 'peter': 1869, 'futurist': 1082, 'inspire': 1341, 'century': 421, 'proverb': 2014, 'engage': 868, 'public': 2022, 'pa': 1816, 'real': 2078, 'completely': 541, 'miss': 1661, 'point': 1917, 'read': 2076, 'send': 2273, 'asinine': 166, 'action': 31, 'trend': 2645, 'young': 2848, 'figure': 1003, 'linea': 1511, 'future': 1081, 'modern': 1671, 'workplace': 2829, 'dependent': 711, 'join': 1398, 'robust': 2181, 'inquiry': 1330, 'leak': 1474, 'theory': 2568, 'nowy': 1761, 'nach': 1716, 'family': 971, 'joke': 1400, 'dynamite': 825, 'renew_democracy': 2130, 'free': 1067, 'artistic': 164, 'expression': 940, 'component': 544, 'democracy': 703, 'unsurprising': 2712, 'threat': 2578, 'paula_piccard': 1849, 'generation': 1108, 'drug': 815, 'discovery': 756, 'slender': 2348, 'finger': 1012, 'bury': 360, 'trump': 2661, 'gallon': 1087, 'record': 2094, 'unemployment': 2695, 'peace': 1851, 'pressure': 1966, 'congress': 554, 'block': 292, 'camp': 377, 'moment': 1674, 'occupation': 1775, 'girl': 1121, 'kind': 1437, 'avoid': 199, 'plague': 1896, 'high': 1217, 'trade': 2622, 'stock': 2437, 'exchange': 919, 'wed': 2794, 'officially': 1782, 'achieve': 27, 'final': 1006, 'unite': 2700, 'villa': 2752, 'stadium': 2413, 'kick': 1432, 'pretty': 1968, 'remind': 2127, 'human': 1252, 'freedom': 1068, 'source': 2382, 'development': 732, 'technology': 2537, 'count': 598, 'genuinely': 1113, 'athlete': 178, 'exist': 926, 'fortuitous': 1057, 'happen': 1183, 'overnight': 1810, 'stay': 2430, 'consistent': 559, 'patient': 1847, 'absolutely': 16, 'wild': 2812, 'spirit': 2397, 'innovation': 1329, 'racism': 2053, 'security': 2263, 'issue': 1380, 'field': 997, 'reason': 2082, 'research': 2145, 'medium': 1618, 'coverage': 608, 'bias': 266, '_phazzma': 9, 'dont': 791, 'stupid': 2467, 'surprise': 2503, 'navy': 1730, 'seemingly': 2267, 'change': 436, 'tank': 2525, 'summer': 2486, 'quick': 2047, 'sleeveless': 2347, 'cantilever': 389, 'run': 2200, 'train': 2629, 'basketball': 238, 'loose': 1530, 'watch': 2785, 'club': 494, 'mark': 1587, 'york': 2847, 'office': 1779, 'movie': 1696, 'step': 2434, 'hold': 1228, 'will': 2813, 'sabihah_r': 2204, 'nose': 1754, 'extreme': 948, 'bmj_latest': 297, 'assign': 169, 'harm': 1188, 'proxy': 2018, 'overstate': 1812, 'get': 1116, 'alike': 84, 'unaware': 2684, 'respect': 2155, 'epitome': 884, 'correction': 589, 'dramatic': 804, 'battle': 241, 'tiny': 2592, 'hedge': 1207, 'code': 502, 'exploration': 936, 'computer': 546, 'available': 195, 'personal': 1865, 'robot': 2180, 'engineer': 870, 'sans': 2222, 'genre': 1111, 'nous': 1758, 'seven': 2281, 'singularity_net': 2332, 'drive': 810, 'show': 2313, 'leave': 1477, 'medal': 1614, 'examine': 912, 'critically': 625, 'personally': 1866, 'blame': 287, 'suppose': 2494, 'piracy': 1891, 'commandeer': 524, 'huge': 1251, 'system': 2517, 'facial': 953, 'recognition': 2091, 'reveal': 2164, 'emotion': 855, 'test': 2554, 'basically': 235, 'distribute': 770, 'rajeev_ankita': 2062, 'government': 1141, 'familiar': 970, 'trinity': 2652, 'liquid': 1514, 'extract': 947, 'mellow': 1621, 'potty': 1946, 'helper': 1212, 'juan_dugarte': 1407, 'agua': 70, 'help': 1211, 'actual': 37, 'impossible': 1288, 'lemon': 1481, 'sectioned_': 2262, 'diagnostic': 733, 'category': 411, 'psychiatric': 2020, 'bts_twt': 351, 'international': 1364, 'band': 227, 'debut': 671, 'strong': 2458, 'line': 1510, 'leaf': 1472, 'short': 2309, 'bench': 259, 'imagine': 1277, 'lose': 1531, 'middle': 1643, 'pandemic': 1827, 'local': 1522, 'shut': 2315, 'year': 2842, 'obvious': 1773, 'accurate': 26, 'correctly': 590, 'rich': 2170, 'fair': 960, 'treat': 2643, 'oral': 1796, 'kindly': 1438, 'number': 1763, 'agora': 68, 'hockey': 1227, 'bear': 245, 'role': 2184, 'inspiration': 1340, 'idiot': 1267, 'return': 2163, 'begin': 252, 'country': 599, 'suicide': 2481, 'song': 2375, 'person': 1864, 'long': 1526, 'swear': 2512, 'ultimate': 2683, 'calm': 375, 'actually': 38, 'loud': 1534, 'adverse': 54, 'effect': 840, 'olive': 1785, 'lame': 1453, 'half': 1180, 'senator': 2272, 'president': 1964, 'decline': 678, 'scientist': 2244, 'nurse': 1764, 'golf': 1134, 'favorite': 981, 'participate': 1840, 'text': 2556, 'azure': 209, 'wrong': 2839, 'food': 1037, 'education': 838, 'income': 1300, 'rotochop_': 2192, 'n_izzah': 1714, 'stem': 2433, 'spread': 2406, 'poorly': 1929, 'strade': 2445, 'hora': 1243, 'manto': 1578, 'supper': 2490, 'tomorrow': 2600, 'enforcement': 867, 'torch': 2608, 'benefit': 261, 'special': 2388, 'miracle': 1657, 'town': 2618, 'insignificant': 1338, 'barcelona': 230, 'bother': 315, 'stop': 2441, 'electric': 848, 'road': 2178, 'remote': 2128, 'plan': 1897, 'indirect': 1309, 'criterion': 623, 'startimes_ng': 2423, 'phone': 1877, 'tonight': 2601, 'fly': 1030, 'flight': 1026, 'attendant': 183, 'mrcee_': 1700, 'wait': 2774, 'donizquierdo_': 790, 'viola': 2755, 'fletcher': 1025, 'survivor': 2506, 'witness': 2822, 'bad': 216, 'fascist': 976, 'jury': 1413, 'maternal': 1607, 'instinct': 1344, 'gentle': 1112, 'literally': 1517, 'the_otheret': 2562, 'grow': 1166, 'tire': 2593, 'set': 2280, 'arbitrary': 148, 'vaccination': 2730, 'hospitalization': 1247, 'metric': 1637, 'unmask': 2705, 'death': 668, 'khan': 1431, 'defamation': 686, 'isabella_kam': 1378, 'legally': 1480, 'liable': 1494, 'dutch': 821, 'court': 605, 'bucket': 352, 'remarkable': 2125, 'wear': 2791, 'recent': 2088, 'staff': 2414, 'prior': 1981, 'report': 2138, 'deliberation': 694, 'pride': 1973, 'decide': 674, 'importance': 1286, 'gender': 1103, 'ruin': 2198, 'perfectly': 1860, 'matin': 1608, 'exception': 918, 'soon': 2376, 'teacher': 2530, 'minster': 1655, 'sheerness': 2296, 'kent': 1425, 'oasis_uk': 1767, 'coward': 610, 'heroic': 1216, 'experience': 932, 'trigger': 2649, 'burnout': 359, 'dip': 750, 'transmission': 2635, 'gidi_traffic': 1119, 'surge': 2500, 'kimuzi_': 1436, 'documentary': 781, 'addict': 44, 'hope': 1240, 'intrigue': 1367, 'hour': 1249, 'shake': 2286, 'japan': 1384, 'fossil': 1060, 'broadcast': 338, 'event': 904, 'swati_mishr': 2511, 'prestigious': 1967, 'paper': 1831, 'winter': 2818, 'solstice': 2371, 'canvas': 390, 'paint': 1823, 'michael_saylor': 1640, 'solder': 2368, 'head': 1197, 'discus': 757, 'license': 1499, 'corruption': 592, 'standard': 2419, 'beloved': 258, 'blizzard': 291, 'global': 1126, 'finale': 1007, 'aura': 190, 'tout': 2617, 'terrain': 2551, 'zoom': 2852, 'stress': 2453, 'move': 1694, 'talk': 2523, 'enerlis_fr': 865, 'commune': 533, 'give': 1123, 'coal': 497, 'waste': 2784, 'problem': 1989, 'financial': 1010, 'incentive': 1295, 'clean': 481, 'form': 1051, 'commercialize': 528, 'tech': 2534, 'idea': 1265, 'solve': 2373, 'resource': 2154, 'cancer': 383, 'goodness': 1137, 'sake': 2213, 'immune': 1280, 'shameful': 2289, 'humanity': 1253, 'try': 2665, 'scientific': 2242, 'information': 1317, '_gifn': 3, 'conte': 570, 'departure': 709, 'inter': 1357, 'manager': 1565, 'merry': 1632, 'round': 2193, 'swing': 2514, 'hilarious': 1220, 'ball': 222, 'properly': 2008, 'dick': 737, 'current': 639, 'republic': 2142, 'entire': 876, 'south': 2383, 'golden': 1133, 'reach': 2075, 'struggle': 2461, 'chain': 430, 'develop': 731, 'million': 1650, 'delve': 699, 'queen': 2043, 'street': 2451, 'virtual': 2759, 'tour': 2615, 'workshop': 2830, 'channel': 437, 'barry': 231, 'currency': 638, 'swap': 2509, 'green': 1155, 'target': 2528, 'competency': 538, 'bonus': 305, 'throw': 2582, 'commitment': 530, 'father': 979, 'child': 456, 'proper': 2007, 'chil': 455, 'alternate': 96, 'method': 1635, 'exam': 911, 'rule': 2199, 'reduce': 2097, 'relative': 2117, 'appeal': 139, 'commercial': 527, 'end': 861, 'mourn': 1693, 'risk': 2176, 'musk': 1710, 'repeat': 2134, 'micro': 1642, 'polish': 1920, 'ministry': 1653, 'favor': 980, 'yellow': 2843, 'submarine': 2471, 'insist': 1339, 'vaccine': 2731, 'myocarditis': 1712, 'actufoot_': 39, 'implication': 1284, 'boost_gmcr': 309, 'session': 2279, 'inclusive': 1299, 'physical': 1881, 'activity': 35, 'challenge': 432, 'skin': 2342, 'religion': 2122, 'politics': 1922, 'custom': 643, 'fashion': 977, 'small': 2354, 'business': 362, 'owner': 1814, 'candidacy': 384, 'ardent_ngl': 150, 'awful': 206, 'administration': 50, 'admission': 52, 'yeah': 2841, 'draft': 801, 'view': 2751, 'order': 1800, 'term': 2550, 'invest': 1369, 'register': 2109, 'democrat': 704, 'bleeding_crypto': 288, 'holy': 1229, 'crap': 611, 'asleep': 167, 'thankfully': 2559, 'wake': 2775, 'pediatrician': 1854, 'pray': 1954, 'beth': 265, 'gall': 1086, 'tromp': 2657, 'fort': 1054, 'come': 519, 'stroke': 2457, 'exams_online': 914, 'secretary': 2261, 'lie': 1500, 'corta': 593, 'super': 2488, 'fiesta': 998, 'absolute': 15, 'mankind': 1573, 'embrace': 854, 'distinct': 769, 'voice': 2767, 'liberal': 1496, 'trillion': 2650, 'inflation': 1315, 'foolishness': 1039, 'endorse': 863, 'project': 2001, 'possible': 1938, 'nature': 1727, 'look': 1528, 'flag': 1021, 'essex_sviu': 898, 'range': 2066, 'rover': 2195, 'steal': 2431, 'save': 2226, 'daily': 647, 'thank': 2557, 'mask': 1597, 'herd': 1213, 'science': 2241, 'jennifer_arcuri': 1391, 'invisible': 1375, 'sandra_tlibe': 2219, 'identify': 1266, 'dermatology': 717, 'assist': 171, 'unveil': 2713, 'surely': 2498, 'bomb': 303, 'gaff': 1083, 'pronto': 2005, 'exit': 928, 'currently': 640, 'school': 2239, 'enforce': 866, 'movement': 1695, 'tonite': 2602, 'bold': 302, 'beautifully': 248, 'writ': 2837, 'accord': 25, 'worth': 2832, 'beach': 243, 'click': 485, 'instant': 1342, 'access': 22, 'professor': 1996, 'nervous': 1740, 'apply': 143, 'vocational': 2766, 'mentor': 1629, 'network': 1741, 'disrespectful': 766, 'dd_bun_': 661, 'shape': 2291, 'magnificent': 1551, 'sadly': 2208, 'repeatedly': 2135, 'baccwoodz_': 211, 'jean': 1388, 'butt': 366, 'simultaneously': 2330, 'misuse': 1666, 'illegal': 1273, 'sale': 2215, 'narcotic': 1719, 'punishable': 2027, 'demonbob_badman': 705, 'safety': 2210, 'chemical': 451, 'plant': 1900, 'laboratory': 1450, 'jeep': 1389, 'ford': 1047, 'bronco': 340, 'badlands': 219, 'eric': 887, 'factory': 956, 'revolution': 2169, 'place': 1894, 'poor': 1928, 'fire': 1014, 'apartment': 133, 'tendril': 2548, 'mist': 1663, 'caress': 401, 'cheek': 449, 'ghost': 1117, 'brush': 345, 'productivity': 1993, 'npc_india_gov': 1762, 'squad': 2410, 'its_conscious': 1382, 'birthday': 280, 'scraboutcha__': 2250, 'manger': 1570, 'auditor': 188, 'throwback': 2583, 'wrap': 2833, 'member': 1623, 'executive': 923, 'committee': 531, 'proprietor': 2010, 'extensive': 944, 'mood': 1683, 'private': 1985, 'bright': 333, 'profusely': 1998, 'rush': 2202, 'resuscitation': 2162, 'wide': 2808, 'significant': 2320, 'quality': 2040, 'proof': 2006, 'stake': 2416, 'penis': 1857, 'hasta': 1192, 'spoiler': 2398, 'fairness': 961, 'complex': 542, 'different': 741, 'type': 2678, 'copa': 581, 'especial': 892, 'track': 2621, 'dope': 794, '_allstripes': 0, 'advocate': 57, 'generalize': 1105, 'lymphatic': 1546, 'anomaly': 123, 'disease': 759, 'alliance': 89, 'easy': 832, 'guide': 1170, 'choose': 461, 'algorithm': 82, 'deafen': 665, 'silence': 2321, 'blue': 296, 'contra': 574, 'familia': 969, '_celia_bedelia_': 1, 'doubt': 797, 'comment': 526, 'scientifically': 2243, 'medically': 1617, 'utterly': 2728, 'foolish': 1038, 'socially': 2363, 'excite': 920, 'brit': 337, 'newsletter': 1743, 'write': 2838, 'alongside': 93, 'k_jeanpierre': 1417, 'mountain': 1692, 'park': 1838, 'tiver': 2595, 'falsely': 968, 'memorial': 1625, 'travel': 2642, 'weekend': 2797, 'maryam_rajavi': 1594, 'anti': 127, 'regime': 2105, 'continue': 573, 'hail': 1177, 'founder': 1062, 'chairwoman': 431, 'excellency': 916, 'confirm': 552, 'political': 1921, 'cable': 372, 'host': 1248, 'life': 1501, 'racist': 2054, 'successful': 2476, 'pale': 1824, 'campus': 379, 'parade': 1833, 'purpose': 2032, 'megawatt': 1620, 'electricity': 849, 'offshore': 1783, 'wind': 2815, 'cost': 594, 'debate': 669, 'ttm_original': 2668, 'afford': 60, 'rand': 2064, 'sacrifice': 2207, 'notion': 1756, 'common': 532, 'secret': 2260, 'practical': 1951, 'relate': 2115, 'jewelry': 1395, 'collectable': 507, 'trivia': 2655, 'fantastic': 974, 'dynamic': 824, 'equilibrium': 885, 'policy': 1919, 'process': 1990, 'durant': 819, 'western': 2803, 'conference': 551, 'gesture': 1115, 'chris_gates': 462, 'expensive': 931, 'aswell': 177, 'poacher': 1912, 'cant': 388, 'outrigger': 1807, 'canoe': 387, 'paddle': 1820, 'culture': 636, 'play': 1906, 'sleep': 2346, 'paranoid': 1834, 'lay': 1468, 'veteran': 2746, 'coma': 515, 'fortnight': 1056, 'pmik_layyahpackage': 1911, 'insurance': 1348, 'provide': 2015, 'chase': 443, 'accessible': 23, 'plasma': 1901, 'sisana__g': 2334, 'cedarwood': 414, 'provitamin': 2017, 'strengthen': 2452, 'hair': 1178, 'improve': 1290, 'growth': 1167, 'shop': 2307, 'verdict': 2742, 'royal': 2196, 'elle': 851, 'iconic': 1263, 'misunderstand': 1665, 'lot': 1533, 'associate': 173, 'maria': 1584, 'digit': 746, 'china': 458, 'back': 212, 'expansion': 929, 'nwary_usa': 1766, 'market': 1588, 'base': 233, 'hong': 1237, 'lens': 1485, 'heel': 1208, 'acne': 28, 'doctor_oxford': 780, 'sheer': 2295, 'relief': 2121, 'hear': 1203, 'finally': 1008, 'responsibility': 2157, 'everyday': 906, 'grateful': 1151, 'virgin': 2758, 'cognition': 504, 'assistant': 172, 'push': 2034, 'behavioral': 254, 'altafhussain_': 94, 'tragedy': 2626, 'chapter': 438, 'brutal': 346, 'kill': 1433, 'razor': 2074, 'virus': 2761, 'amienya_': 106, 'university': 2703, 'insensitive': 1333, 'expect': 930, 'disclose': 755, 'accept': 21, 'receive': 2087, 'table': 2518, 'faz_sport': 982, 'majid_agha': 1558, 'cardiac': 397, 'swat': 2510, 'deceitful': 673, 'fraudulent': 1066, 'slimy': 2350, 'little': 1519, 'weasel': 2792, 'awareness': 203, 'site': 2335, 'universal': 2701, 'museum': 1708, 'error': 888, 'negligence': 1738, 'manslaughter': 1577, 'charge': 440, 'career': 399, 'series': 2276, 'in_bureau': 1291, 'cry': 633, 'baseball': 234, 'bend': 260, 'grit': 1161, 'championship': 433, 'epidemic': 882, 'gear': 1101, 'folk': 1033, 'kimari_kun': 1435, 'mange': 1569, 'bambalal_bjp': 224, 'yogi': 2846, 'supporter': 2493, 'reverse': 2166, 'fresh': 1070, 'import': 1285, 'location': 1523, 'landmark': 1458, 'judge': 1409, 'legal': 1479, 'doge': 783, 'card': 396, 'purchase': 2030, 'gold': 1132, 'deep__ai': 683, 'vocabulary': 2765, 'raid': 2060, 'follow': 1034, 'fidelity': 996, 'spot': 2404, 'hamburger': 1181, 'healthy': 1202, 'satellite': 2224, 'vulnerable': 2771, 'profit': 1997, 'injustice': 1327, 'stooge': 2440, 'incase': 1294, 'forward': 1059, 'even': 903, 'la_kunma': 1447, 'oreina_fuck': 1802, 'footage': 1041, 'drag': 802, 'encourage': 859, 'transparent': 2636, 'roll': 2185, 'prison': 1983, 'monte': 1680, 'search': 2256, 'plastic': 1902, 'prince': 1979, 'sound': 2380, 'jav_grandpa': 1385, 'gross': 1164, 'hate': 1193, 'cheat': 445, 'actress': 36, 'michigan': 1641, 'apologize': 135, 'party': 1842, 'agree': 69, 'jest': 1394, 'tweet': 2674, 'contact': 569, 'trace': 2620, 'reduction': 2098, 'wave': 2787, 'ongoing': 1787, 'investigation': 1371, 'ndcs_cymru': 1731, 'deaf': 664, 'age': 65, 'contribute': 577, 'colin_sylvester': 506, 'consider': 557, 'guess': 1169, 'utilize': 2727, 'function': 1076, 'zero': 2851, 'testa': 2555, 'version': 2743, 'ugly': 2682, 'good': 1136, 'operate': 1789, 'generate': 1107, 'spring_bing': 2408, 'major': 1559, 'david_turnbull': 658, 'undying': 2694, 'journalist': 1405, 'conclude': 549, 'scope': 2246, 'teal': 2531, 'subscription': 2473, 'kirti__': 1441, 'mahi_': 1553, 'manoj_m_dev': 1576, 'real_aditi': 2079, 'krisu_': 1445, 'manisha_': 1572, 'bean': 244, 'brand': 324, 'room': 2187, 'paraphernalia': 1835, 'stuff': 2465, 'jnbb__': 1397, 'prim': 1974, 'midwife': 1646, 'commissioner': 529, 'state': 2424, 'governor': 1142, 'guardian': 1168, 'deliciously': 695, 'petty': 1875, 'spat': 2386, 'deep': 682, 'victory': 2749, 'expert': 933, 'statement': 2425, 'morgan': 1686, 'bounce': 317, 'coral': 582, 'harbour': 1186, 'inlet': 1328, 'route': 2194, 'principal': 1980, 'deputy': 716, 'press': 1965, 'class': 478, 'lawsuit': 1467, 'federal': 985, 'cause': 412, 'mention': 1628, 'bien': 267, 'football': 1042, 'close': 490, 'revenue': 2165, 'gymnastics': 1174, 'kitten': 1442, 'resistance': 2151, 'approach': 145, 'aviation': 198, 'transport': 2637, 'marine': 1585, 'suggest': 2480, 'smart': 2355, 'impressive': 1289, 'canal': 381, 'primero': 1978, 'selfish': 2270, 'arrogant': 159, 'hateful': 1194, 'society': 2364, 'idiotic': 1268, 'lr_sportred': 1537, 'brad': 321, 'nick': 1746, 'ross': 2191, 'beard': 246, 'tory': 2611, 'harper': 1190, 'undiagnosed': 2691, 'mother': 1690, 'esile_cl': 891, 'box': 320, 'corner': 583, 'jay_quigley': 1386, 'night': 1748, 'fantasia': 973, 'asad_umar': 165, 'registration': 2110, 'insidiousness': 1336, 'male': 1561, 'coach': 496, 'insult': 1347, 'size': 2338, 'curt': 641, 'miller': 1649, 'siregift_': 2333, 'welcome': 2800, 'season': 2257, 'unreasonably': 2709, 'charm': 441, 'crush': 632, 'result': 2161, 'wealthy': 2790, 'thankful': 2558, 'keshab_mahanta': 1428, 'behalf': 253, 'visual': 2763, 'consistency': 558, 'admire': 51, 'wil_da_beast': 2811, 'insanely': 1332, 'ban': 226, 'certain': 423, 'critical': 624, 'classical': 479, 'bigotry': 269, 'brilliant': 334, 'planet': 1899, 'agar': 64, 'agenda': 67, 'face': 952, 'ahead': 71, 'schedule': 2238, 'compact': 535, 'adaobi_igwee': 42, 'beg': 251, 'urgently': 2722, 'amplify': 107, 'slowly': 2351, 'boot': 311, 'economy': 835, 'vinaydixit_': 2753, 'justice': 1414, 'kalo': 1420, 'masjid': 1596, 'ancora': 114, 'export': 938, 'truth': 2663, 'smith': 2357, 'correct': 588, 'coup': 601, 'acquaint': 29, 'brain': 323, 'depiction': 712, 'score': 2247, 'maintenance': 1557, 'water': 2786, 'heater': 1206, 'temp': 2543, 'determine': 728, 'glad': 1125, 'claim': 476, 'affluence': 59, 'space': 2384, 'especially': 893, 'shame': 2288, 'evidence': 907, 'animal': 120, 'spurs_four': 2409, 'polo_prototype': 1925, 'golaco_tv': 1131, 'parent': 1836, 'spor': 2400, 'urge': 2720, 'fellow': 989, 'cbngov_akin': 413, 'scandal': 2230, 'apoorva_nyc': 136, 'scoop': 2245, 'investigate': 1370, 'teen': 2538, 'vaccina': 2729, 'light': 1505, 'mano': 1575, 'example': 913, 'provincial': 2016, 'root': 2189, 'rooster': 2188, 'stick': 2436, 'bat': 239, 'rope': 2190, 'totally': 2613, 'multiple': 1704, '_levagabond': 5, 'manga': 1568, 'alex_dm': 81, 'padre': 1821, 'study': 2464, 'brief': 332, 'article': 161, 'early': 827, 'dichotomy': 736, 'datascience__': 656, 'cell': 417, 'image': 1275, 'burglary': 356, 'jordan': 1402, 'finance': 1009, 'lesley_faith': 1488, 'appallingly': 137, 'joint': 1399, 'declaration': 676, 'badge': 218, 'deadline': 662, 'loom': 1529, 'midnight': 1644, 'spaghetti': 2385, 'doon': 792, 'unbothered': 2685, 'physic': 1880, 'cricketer': 618, 'crook': 626, 'department': 708, 'civil': 474, 'coffee': 503, 'whoa': 2807, 'leadership': 1471, 'impact': 1282, 'active': 32, 'drill': 806, 'neighborhood': 1739, 'unsafe': 2710, 'poddy': 1914, 'concern': 548, 'mort': 1689, 'outstanding': 1809, 'horrendous': 1245, 'tragic': 2627, 'wise': 2820, 'investment': 1372, 'talent': 2522, 'pinnacle': 1889, 'honest': 1234, 'figga_dilla': 1000, 'undertake': 2690, 'surgery': 2501, 'individual': 1310, 'home': 1230, 'feature': 984, 'quit': 2049, 'back_fis': 213, 'meter': 1634, 'update': 2714, 'audience': 187, 'felt': 991, 'scratch': 2252, 'vegetarian': 2740, 'criminal': 620, 'cut': 645, 'jealousy': 1387, 'injurious': 1326, 'brazil': 326, 'advise': 56, 'arghavan_salles': 153, 'land': 1457, 'primary_immune': 1976, 'lung': 1543, 'damage': 649, 'persistent': 1863, 'reopen': 2133, 'extent': 945, 'option': 1793, 'promise': 2003, 'reality': 2080, 'definitely': 691, 'slide': 2349, 'pote': 1943, 'fondly': 1035, 'formidable': 1052, 'historian': 1223, 'jennifer_hiller': 1392, 'extend': 942, 'tier': 2588, 'buzz': 369, 'ecstasy': 836, 'loyal': 1536, 'ssozinha__': 2412, 'slave': 2345, 'martial': 1591, 'garyusher_': 1094, 'kala_manchester': 1418, 'cotton': 595, 'conspiracy': 560, 'theorist': 2567, 'biological': 275, 'warfare': 2779, 'knowledge': 1444, 'quina': 2048, 'icymi_py': 1264, 'homemade': 1232, 'python': 2036, 'popular': 1930, 'interactive': 1358, 'demo': 702, 'immunity': 1281, 'possibly': 1939, 'lifetime': 1503, 'sturgeons_law': 2468, 'general': 1104, 'opponent': 1791, 'monopolize': 1678, 'gekko_wynv': 1102, 'deplorable': 713, 'crowd': 628, 'independent': 1304, 'fury': 1080, 'lifeline': 1502, 'near': 1732, 'clutch': 495, 'buzzer': 370, 'postseason': 1942, 'weed': 2795, 'rag': 2058, 'chronic': 463, 'pain': 1822, 'athletic': 179, 'ohno_vision_g': 1784, 'chicken': 453, 'waffle': 2772, '_emjohnston': 2, 'equity': 886, 'program': 1999, 'porter': 1933, 'creation': 615, 'marc_marhone': 1580, 'whinny': 2805, 'bitch': 282, 'earn': 828, 'tolerate': 2598, 'port': 1932, 'petit': 1870, 'king': 1439, 'bizarre': 284, 'attack': 181, 'bird': 277, 'quantum': 2041, 'official': 1781, 'trailer': 2628, 'circle': 467, 'lin_manuel': 1508, 'ironically': 1376, 'nationalism': 1724, 'isolationism': 1379, 'opinion': 1790, 'indication': 1307, 'generosity': 1109, 'forbid': 1045, 'brooklynt_brown': 341, 'title': 2594, 'posse': 1937, 'sort': 2379, 'fee': 986, 'burner': 358, 'melt': 1622, 'blow': 295, 'lady': 1451, 'trilogy': 2651, 'description': 718, 'monkey': 1677, 'thread': 2577, 'garrafa': 1093, 'anda': 115, 'olla': 1786, 'gregg_mashberg': 1157, 'mr_markjacobs': 1699, 'modest': 1673, 'proposal': 2009, 'tanker': 2526, 'atlantic': 180, 'explain': 934, 'grant': 1148, 'status': 2428, 'auto_moto_pl': 194, 'hand': 1182, 'permanent': 1862, 'stance': 2417, 'prime': 1977, 'initiative_book': 1323, 'pick': 1882, 'spotlight': 2405, 'spring': 2407, 'apparently': 138, 'pocket': 1913, 'shoulder': 2312, 'leather': 1476, 'purse': 2033, 'luxury': 1545, 'purple': 2031, 'ranger': 2067, 'lush_carter': 1544, 'single': 2331, 'evolve': 909, 'cg_trader': 429, 'upside': 2717, 'picum_post': 1883, 'undocumented': 2693, 'regional': 2108, 'book': 307, 'sell': 2271, 'haver': 1195, 'diversion': 776, 'arrive': 157, 'defeat': 687, 'strategy': 2449, 'chevron': 452, 'frank': 1065, 'bos': 313, 'mama_soypaquito': 1562, 'auto': 193, 'tuber': 2669, 'think': 2573, 'qualify': 2039, 'dice': 735, 'mani': 1571, 'dislike': 761, 'parliamentary': 1839, 'jess_birky': 1393, 'trappist': 2640, 'mocha_jesus': 1669, 'poster': 1941, 'courtesy': 606, 'queensberry': 2044, 'cabinet': 371, 'journalism': 1404, 'drink': 807, 'initial': 1319, 'furry': 1079, 'dong': 789, 'naik': 1718, 'motor': 1691, 'juanpa_smith': 1408, 'subscribe': 2472, 'pete_grieve': 1868, 'likely': 1506, 'mandate': 1566, 'ordinance': 1801, 'amend': 104, 'compos': 545, 'foot': 1040, 'allow': 91, 'approximate': 146, 'odds': 1777, 'fast': 978, 'sultan': 2484, 'delta': 697, 'ponga': 1926, 'select': 2268, 'sorry': 2378, 'drought': 814, 'north': 1753, 'puzzle': 2035, 'reflect': 2101, 'failure': 958, 'bless': 289, 'prepare': 1961, 'salad': 2214, 'drop': 813, 'window': 2816, 'football__tweet': 1043, 'time': 2591, 'marcher': 1582, 'essayer': 895, 'all': 87, 'estadio': 900, 'decade': 672, 'stone': 2439, 'pilot': 1886, 'basket': 237, 'color': 513, 'door': 793, 'combat': 516, 'liar': 1495, 'soft': 2365, 'supreme': 2496, 'nourishment': 1757, 'enrich': 873, 'coconut': 501, 'wash': 2783, 'lunar': 1541, 'the_ks': 2561, 'recommendation': 2093, 'engine': 869, 'similar': 2325, 'evolution': 908, 'cuisine': 634, 'region': 2107, 'publicly': 2024, 'internal': 1363, 'memo': 1624, 'casualty': 409, 'empathy': 857, 'soup': 2381, 'broth': 342, 'sesame': 2278, 'gradually': 1144, 'increase': 1302, 'decrease': 679, 'premier': 1957, 'production': 1992, 'storytelling': 2444, 'professional': 1994, 'wrestle': 2836, 'minority': 1654, 'unprecedented': 2707, 'transformation': 2634, 'voluntarily': 2768, 'hell': 1209, 'magazine': 1550, 'resort': 2152, 'word': 2826, 'lemonade': 1482, 'august': 189, 'sign': 2318, 'spend': 2394, 'boo_rady': 306, 'journey': 1406, 'consultation': 565, 'conduct': 550, 'undefeated': 2687, 'unique': 2698, 'date': 657, 'rescue_uk': 2144, 'patron': 1848, 'trip': 2653, 'carr': 402, 'noir': 1750, 'thesis': 2572, 'aware': 202, 'divisive': 778, 'lewis': 1493, 'recently': 2089, 'panel': 1829, 'perspective': 1867, 'modernization': 1672, 'redemptive': 2096, 'church': 465, 'thornburg_amaya': 2575, 'disrespect': 765, 'nominate': 1752, 'studio': 2463, 'azeri_mamedov': 208, 'turkey': 2671, 'puppet': 2029, 'bute_house': 365, 'seat': 2258, 'fegtoken_iran': 988, 'oracle': 1795, 'contract': 575, 'integration': 1350, 'header': 1198, 'hello': 1210, 'combination': 517, 'maha': 1552, 'obsession': 1772, 'rape': 2069, 'deepen': 684, 'carbon': 395, 'gory': 1139, 'resign': 2149, 'intensify': 1355, 'wird': 2819, 'alien': 83, 'pineapple_fussy': 1888, 'ranch': 2063, 'square': 2411, 'brochure': 339, 'surfer': 2499, 'german': 1114, 'berlin': 262, 'suit': 2482, 'sportswear': 2403, 'fitness': 1019, 'balm': 223, 'gloss': 1127, 'raga_reports': 2059, 'cross': 627, 'commend': 525, 'seventeen': 2282, 'winner': 2817, 'idol': 1269, 'anna': 121, 'county': 600, 'army': 155, 'pending': 1856, 'minute': 1656, 'amen': 103, 'tight': 2589, 'capability': 391, 'tain': 2519, 'answer': 125, 'senior': 2274, 'necessary': 1735, 'dangbanarep_': 653, 'victor': 2748, 'platform': 1904, 'refresh': 2102, 'unsold': 2711, 'trap': 2639, 'raffle': 2057, 'donate': 788, 'affect': 58, 'clearing_fog': 484, 'alec': 79, 'dismantle': 762, 'fail': 957, 'faith': 962, 'worker': 2828, 'able': 14, 'quack': 2037, 'businessman': 363, 'misinformation': 1660, 'fully': 1075, 'akams_': 75, 'being_battalion': 255, 'noise': 1751, 'last': 1461, 'hero': 1215, 'power': 1949, 'matric': 1609, 'educational': 839, 'shafqat_mahmood': 2284, 'aly_ft_rkv': 99, 'sheeter': 2297, 'arena': 152, 'match': 1604, 'cocktail': 500, 'coast': 498, 'densely': 706, 'pollute': 1923, 'debris': 670, 'vessel': 2745, 'wreckage': 2835, 'float': 1028, 'tune': 2670, 'solution': 2372, 'simple': 2328, 'clown': 493, 'frame': 1063, 'maybe': 1611, 'there': 2571, 'backup': 214, 'salomon': 2217, 'obligation': 1770, 'privilege': 1986, 'akozyrev_': 76, 'rural': 2201, 'tribal': 2647, 'walk': 2776, 'screen': 2253, 'defence': 688, 'smell': 2356, 'remain': 2124, 'gunshot': 1172, 'whilst': 2804, 'incident': 1296, 'territory': 2553, 'petition': 1871, 'inevitable': 1313, 'eventually': 905, 'leverage': 1492, 'borrow': 312, 'fall': 965, 'embassy': 852, 'poem': 1916, 'nice': 1745, 'piece': 1884, 'forthcoming': 1055, 'collection': 508, 'toxic': 2619, 'trait': 2631, 'certificate': 425, 'applicability': 141, 'heartbreaking': 1205, 'adaeze_uc': 40, 'police': 1918, 'uncle': 2686, 'unknown': 2704, 'gunman': 1171, 'weirdly': 2799, 'elderly': 845, 'diesel': 739, 'psychiatry': 2021, 'boost': 308, 'iane_menezes': 1261, 'centavo': 419, 'screw': 2254, 'dramatically': 805, 'rein': 2112, 'promotion': 2004, 'destiny_thememe': 723, 'birgit_kelle': 278, 'syncope': 2515, 'intake': 1349, 'publicnews_com': 2025, 'tiara_schmidt': 2585, 'simply': 2329, 'awesome': 205, 'despite': 722, 'large': 1459, 'rebuild': 2085, 'burden': 354, 'terrible': 2552, 'simon_s': 2326, 'leader': 1470, 'cesspit': 427, 'socialist': 2362, 'anarchy': 112, 'sham': 2287, 'scrap': 2251, 'summary': 2485, 'sentence': 2275, 'gather': 1099, 'eat': 833, 'disorder': 763, 'medalist': 1615, 'cest__carre': 428, 'city': 472, 'valley': 2735, 'shelter': 2299, 'murder': 1705, 'environment': 879, 'scale': 2228, 'antibody': 128, 'enhancement': 871, 'ft_total': 1073, 'granada': 1146, 'danger': 654, 'escalate': 889, 'counselor_': 597, 'win': 2814, 'dominant': 786, 'cultural': 635, 'el_betelito': 843, 'labor': 1449, 'rob_roos': 2179, 'objective': 1769, 'destroy': 724, 'obliterate': 1771, 'astro_elliott': 176, 'aim': 73, 'booster': 310, 'orbital': 1798, 'nightmare': 1749, 'true': 2660, 'embodiment': 853, 'capitalism': 393, 'tough': 2614, 'jolt': 1401, 'awake': 200, 'offer': 1778, 'backwards': 215, 'thrive': 2581, 'average': 197, 'complete': 540, 'goalkeeper': 1129, 'photo': 1878, 'ambitiousvilla_': 102, 'allegedly': 88, 'hack': 1176, 'colonial': 511, 'plane': 1898, 'arrest': 156, 'gauche': 1100, 'astound': 175, 'talon': 2524, 'phase': 1876, 'wall': 2777, 'journal': 1403, 'topic': 2606, 'dama': 648, 'roger': 2183, 'alert': 80, 'episode': 883, 'monthly': 1682, 'rapper': 2070, 'mcm_home': 1612, 'tony': 2604, 'blair': 286, 'bush': 361, 'plump': 1909, 'naughty': 1728, 'threesome': 2580, 'radio_quebec': 2056, 'checker': 448, 'tait': 2520, 'conspiration': 561, 'torture': 2610, 'rise': 2175, 'store': 2442, 'illuminate': 1274, 'discussion': 758, 'boston': 314, 'extremely': 949, 'violent': 2757, 'partner': 1841, 'summit': 2487, 'earthquake': 829, 'detection': 727, 'initiative': 1322, 'viable': 2747, 'path': 1846, 'cahe_ahc': 373, 'include': 1297, 'diverse': 775, 'treatment': 2644, 'trial': 2646, 'stun': 2466, 'dollar': 784, 'mistrust': 1664, 'trustworthy': 2662, 'dev_fadnavis': 729, 'situation': 2336, 'mucormycosis': 1703, 'cute': 646, 'inside': 1335, 'marathon': 1579, 'gypsy': 1175, 'comedy': 520, 'dollar_mashesha': 785, 'bobby': 299, 'release': 2120, 'shortly': 2311, 'difficult': 742, 'define': 690, 'speculation': 2392, 'representation': 2140, 'karen_santiago': 1421, 'shock': 2304, 'hire': 1222, 'statistic': 2427, 'review': 2167, 'advice': 55, 'focus': 1031, 'generally': 1106, 'fish': 1018, 'ancient': 113, 'preparation': 1960, 'martin': 1592, 'assignment': 170, 'arctic': 149, 'anal': 108, 'arsenal': 160, 'grave': 1152, 'petroleum': 1873, 'traditional': 2624, 'lever': 1491, 'griffin': 1159, 'moon': 1684, 'extension': 943, 'admit': 53, 'flammable': 1022, 'initially': 1320, 'ovulation': 1813, 'horny': 1244, 'protect': 2011, 'sexual': 2283, 'troll': 2656, 'carefully': 400, 'chocolate': 460, 'bikini': 270, 'saline': 2216, 'cock': 499, 'award': 201, 'relationship': 2116, 'yhd_': 2845, 'kingdom': 1440, 'fighter': 1002, 'trauma': 2641, 'natural': 1726, 'notice': 1755, 'bridge': 331, 'astonish': 174, 'analysis': 109, 'bandhunta_jugg': 228, 'express': 939, 'emotional': 856, 'recruit': 2095, 'madly': 1549, 'creative': 616, 'sportforlife_': 2402, 'resident': 2147, 'agency': 66, 'immediately': 1278, 'prevent': 1969, 'charts_k': 442, 'lake': 1452, 'shore': 2308, 'sable': 2205, 'browse': 344, 'insightful': 1337, 'kevin_scott': 1429, 'rentable': 2132, 'bravo': 325, 'simone_biles': 2327, 'successfully': 2477, 'double': 796, 'pike': 1885, 'vault': 2739, 'truck': 2659, 'produce': 1991, 'torque': 2609, 'midrange': 1645, 'defender': 689, 'foul': 1061, 'probably': 1988, 'chimney': 457, 'flue': 1029, 'damp': 651, 'cold': 505, 'river': 2177, 'sanitize': 2220, 'essentially': 897, 'bts_bighit': 349, 'bts_butter': 350, 'realize': 2081, 'inaccurate': 1292, 'angeline': 118, 'douche': 798, 'matter': 1610, 'renovation': 2131, 'fence': 993, 'upgrade': 2715, 'mr_alexius': 1698, 'pad': 1819, 'protection': 2012, 'r_marcotorres': 2050, 'apc_ubch': 134, 'minec_aragua': 1651, 'synthetic': 2516, 'greenhouse': 1156, 'nfk_nfk_nfk': 1744, 'virtuously': 2760, 'entrepreneurial': 878, 'cis_studies': 469, 'center': 420, 'cile_center': 466, 'aliya_serena': 86, 'tend': 2547, 'anther': 126, 'breakneck': 329, 'speed': 2393, 'pace': 1817, 'researcher': 2146, 'shift': 2300, 'cheater': 446, 'hustle': 1257, 'lancer': 1456, 'cast': 406, 'bile': 271, 'pediatric': 1853, 'admi': 49, 'typo_cat': 2681, 'footballer': 1044, 'nationwide': 1725, 'prove': 2013, 'sauce': 2225, 'pine': 1887, 'basil': 236, 'vinegar': 2754, 'priority': 1982, 'position': 1935, 'professionally': 1995, 'ts_singhdeo': 2666, 'dose': 795, 'styne_council': 2469, 'traffy__': 2625, 'firstly': 1017, 'kudos': 1446, 'thomas_o_': 2574, 'dazn_de': 660, 'sker': 2339, 'mica': 1638, 'toll': 2599, 'gate': 1097, 'indictment': 1308, 'corrupt': 591, 'certify': 426, 'specialty': 2389, 'metras_global': 1636, 'mobilization': 1668, 'responsible': 2158, 'effort': 842, 'placement': 1895, 'sucre': 2479, 'qualifiedman_': 2038, 'mise': 1659, 'sketch': 2340, 'sarkar': 2223, 'duty': 822, 'cancellation': 382, 'unhappy': 2696, 'headquarter': 1199, 'moron': 1688, 'rest': 2160, 'felsted_busecon': 990, 'lecture': 1478, 'harness': 1189, 'dumb': 818, 'sigh': 2317, 'regardless': 2104, 'underlie': 2688, 'ignorant': 1270, 'call': 374, 'logic': 1525, 'deduction': 680, 'academic': 17, 'busy': 364, 'strip': 2456, 'population': 1931, 'registry': 2111, 'badan': 217, 'baru': 232, 'corona': 585, 'variant': 2737, 'beck': 249, 'materialism': 1606, 'despair': 721, 'bismillah': 281, 'youth': 2849, 'incomparable': 1301, 'explosion': 937, 'muse': 1707, 'shan': 2290, 'sick': 2316, 'intelligent': 1353, 'skilled': 2341, 'crucial': 629, 'slap': 2343, 'freeze': 1069, 'interfere': 1360, 'topple': 2607, 'wary': 2782, 'trainee': 2630, 'economic': 834, 'capital': 392, 'wagon': 2773, 'strict': 2454, 'diet': 740, 'specifically': 2391, 'halal': 1179, 'specific': 2390, 'micellar': 1639, 'remover': 2129, 'regimen': 2106, 'mary': 1593, 'management': 1564, 'lode': 1524, 'analyst': 110, 'vali': 2732, 'mix': 1667, 'reeseg_': 2099, 'additional': 45, 'corporation': 587, 'shortage': 2310, 'humanly': 1254, 'lira': 1515, 'value': 2736, 'massacre': 1599, 'anniversary': 122, 'original': 1804, 'active_taylor': 33, 'primary': 1975, 'premium': 1959, 'template': 2544, 'afpe_pe': 61, 'porto': 1934, 'appointment': 144, 'solo': 2370, 'luck': 1539, 'mucor': 1702, 'shree': 2314, 'clinic': 487, 'dissertation': 768, 'pastel': 1844, 'muscle': 1706, 'television': 2541, 'ablaze': 13, 'educate': 837, 'lina': 1509, 'request': 2143, 'attention': 184, 'apart': 131, 'drip': 808, 'coul': 596, 'moral': 1685, 'straightforward': 2447, 'technique': 2536, 'baby': 210, 'tejasvi_surya': 2540, 'interview': 1366, 'authority': 192, 'chief': 454, 'existence': 927, 'm_s_league': 1547, 'dear': 667, 'arriver': 158, 'tennis': 2549, 'andrewchl_': 117, 'imaginate': 1276, 'niece': 1747, 'vehicle': 2741, 'allocation': 90, 'scam': 2229, 'aide': 72, 'rebrand': 2084, 'film': 1005, 'bail': 220, 'launch': 1464, 'contrast': 576, 'shah': 2285, 'abbas': 11, 'literature': 1518, 'pizza': 1893, 'au_tom_otive': 186, 'consumption': 568, 'govern': 1140, 'giveaway': 1124, 'laurendragneel_': 1465, 'romantically': 2186, 'neatly': 1734, 'corolla': 584, 'obas_autos': 1768, 'injection': 1325, 'patel': 1845, 'hasan': 1191, 'throwing_shayde': 2584, 'marguerite_hbc': 1583, 'typical': 2679, 'trader': 2623, 'marry': 1590, 'largo': 1460, 'golfer': 1135, 'manner': 1574, 'weak': 2789, '_pablofdez_': 8, 'adamcrafton_': 41, 'teeth': 2539, 'rank': 2068, 'anon': 124, 'out': 1806, 'progress': 2000, 'brian_slagle': 330, 'twist': 2675, 'btc_archive': 348, 'excuse': 922, 'damn': 650, 'demise': 701, 'compassionate': 537, 'warren': 2781, 'widely': 2809, 'lately': 1463, 'positive': 1936, 'quarantine': 2042, 'canada': 380, 'mass': 1598, 'casually': 408, 'apartheid': 132, 'blockade': 293, 'religious': 2123, 'attitude': 185, 'abbah_': 10, 'colonization': 512, 'construction': 563, 'facility': 954, 'indoor': 1311, 'pool': 1927, 'laminate': 1455, 'timber': 2590, 'structure': 2460, 'inherent': 1318, 'prefer': 1956, 'ignore': 1271, 'traitor': 2632, 'nation': 1722, 'intent': 1356, 'mandatory': 1567, 'aver': 196, 'comfort': 521, 'maritime': 1586, 'consulter': 566, 'diffusion': 743, 'breach': 327, 'entertain': 875, 'representative': 2141, 'ceremony': 422, 'recklessly': 2090, 'alternative': 97, 'thousand': 2576, 'standish': 2420, 'fabulous': 951, 'adjustable': 48, 'deluxe': 698, 'kayak': 1423, 'detachable': 725, 'practice': 1952, 'bowl': 319, 'tapia': 2527, 'maiden': 1554, 'castle': 407, 'stockbroker': 2438, 'goat': 1130, 'blindly': 290, 'compliant': 543, 'unquestionably': 2708, 'deem': 681, 'master': 1603, 'degree': 693, 'liberal_party': 1497, 'iam_lazy': 1260, 'brother': 343, 'shark': 2294, 'cheap': 444, 'giro': 1122, 'fallibility': 966, 'stage': 2415, 'player': 1907, 'angle': 119, 'dwarf': 823, 'therapist': 2570, 'replace': 2136, 'threaten': 2579, 'pand': 1826, 'andrewbowie_mp': 116, 'scot': 2248, 'east': 830, 'dubious': 816, 'premise': 1958, 'drmonika_langeh': 812, 'intrusion': 1368, 'hike': 1219, 'silver': 2324, 'depository': 714, 'warehouse': 2778, 'peak': 1852, 'bureau': 355, 'fan_hawkeye': 972, 'bitter': 283, 'ginger': 1120, 'citronella': 470, 'candle': 386, 'establishment': 899, 'ensure': 874, '_luccak_': 6, 'festival': 994, 'goof': 1138, 'constitution': 562, 'manage': 1563, 'hood': 1238, '_nwai': 7, 'unnecessarily': 2706, 'cruel': 631, 'sack': 2206, 'thee_maveric': 2564, 'potentially': 1945, 'lift': 1504, 'stream': 2450, 'expulsion': 941, 'clear': 483, 'message': 1633, 'caravan': 394, 'swim': 2513, 'radio': 2055, 'genetically': 1110, 'certainly': 424, 'exercise': 924, 'bristol_ml': 336, 'cookpad_dev': 580, 'fain': 959, 'belong': 257, 'lunes': 1542, 'forgive': 1050, 'desire': 720, 'conquer': 555, 'universe': 2702, 'subjugate': 2470, 'civilization': 475, 'index': 1305, 'initiate': 1321, 'surtout': 2504, 'hop': 1239, 'upstate': 2718, 'fireplace': 1015, 'keep': 1424, 'warm': 2780, 'el_reportero': 844, 'shareholder': 2293, 'opposite': 1792, 'paulmitchell_ab': 1850, 'interior': 1362, 'clinical': 488, 'crime': 619, 'karl_lauterbach': 1422, 'schule': 2240, 'seal': 2255, 'bambino': 225, 'paolo': 1830, 'twitch': 2676, 'tribunal': 2648, 'haya': 1196, 'courage': 603, 'honda': 1233, 'civic': 473, 'sedan': 2264, 'jake': 1383, 'elective': 847, 'escape': 890, 'eagle': 826, 'dishwasher': 760, 'rinse': 2173, 'inform': 1316, 'competition': 539, 'chunk': 464, 'ticket': 2586, 'eyesofmercury_': 950, 'prize': 1987, 'success': 2475, 'balance': 221, 'explanation': 935, 'negative': 1737, 'tonsillitis': 2603, 'proxy_impact': 2019, 'tide': 2587, 'alter': 95, 'dinheiro': 749, 'rachaeil_': 2052, 'adjoint': 47, 'cricket': 617, 'clip': 489, 'scenario': 2235, 'sociable': 2360, 'nowadays': 1760, 'digger': 745, 'dig': 744, 'granula': 1149, 'perfect': 1859, 'gateway': 1098, 'bbc_topgear': 242, 'tron': 2658, 'plug': 1908, 'slug': 2352, 'bout': 318, 'ala_pla': 77, 'deeply': 685, 'supremacy': 2495, 'dominate': 787, 'claudio_report': 480, 'flaccid': 1020, 'attempt': 182, 'detect': 726, 'dr_arpit_jain': 799, 'bank': 229, 'residential': 2148, 'gain': 1084, 'straight': 2446, 'orchid': 1799, 'brutally': 347, 'alcohol': 78, 'bottle': 316, 'insert': 1334, 'demand': 700, 'supply': 2491, 'nabil_djellit': 1715, 'gros': 1163, 'essay': 894, 'weather': 2793, 'plate': 1903, 'afternoon': 63, 'font': 1036, 'disturb': 773, 'refusal': 2103, 'alive': 85, 'usually': 2725, 'quench': 2045, 'exhaust': 925, 'academy': 18, 'lamentable': 1454, 'drivable': 809, 'accidentally': 24, 'strongly': 2459, 'merger': 1631, 'oversold': 1811, 'theme': 2565, 'directly': 753, 'confront': 553, 'soldi': 2369, 'tenacity': 2546, 'relax': 2119, 'indiacares_': 1306, 'direction': 752, 'customer': 644, 'initiator': 1324, 'apple': 140, 'cellular': 418, 'gray': 1153, 'aluminum': 98, 'unit': 2699, 'smooth': 2358, 'shoe': 2305, 'loss': 1532, 'relatively': 2118, 'undo': 2692, 'intersection': 1365, 'chino': 459, 'elham_razani': 850, 'beautiful': 247, 'falcon': 964, 'content': 571, 'consume': 567, 'cheer': 450, 'masse': 1601, 'masculine': 1595, 'liberal_slayerr': 1498, 'graduation': 1145, 'mike': 1647, 'msumbanews_': 1701, 'extra': 946, 'eastern': 831, 'hopeful': 1241, 'hydrocarbon': 1259, 'disruption': 767, 'binge': 274, 'eternal': 901, 'declare': 677, 'smug': 2359, 'grinder': 1160, 'deadpan': 663, 'uniform': 2697, 'rider': 2171, 'anubhavmohanty_': 129, 'fortune': 1058, 'honey': 1236, 'infant': 1314, 'uplift': 2716, 'selection': 2269, 'prolific': 2002, 'efficiently': 841, 'responsibly': 2159, 'address': 46, 'massage': 1600, 'inactive': 1293, 'reply': 2137, 'mutual': 1711, 'nasem_health': 1720, 'publication': 2023, 'upstream': 2719, 'crispy': 622, 'tempt': 2545, 'devastate': 730, 'petrolis_merkez': 1874, 'spider_grana': 2395, 'naija_pr': 1717, 'dive': 774, 'instructor': 1346, 'scene': 2236, 'dust': 820, 'origin': 1803, 'solar': 2367, 'grocery': 1162, 'delivery': 696, 'yummyboy_': 2850, 'strange': 2448, 'enjoy': 872, 'truthful': 2664, 'intellectual': 1351, 'grenade': 1158, 'officer': 1780, 'carry': 403, 'jump': 1411, 'accelerate': 20, 'institute': 1345, 'buy': 368, 'sanjay_dixit': 2221, 'lobbyist': 1521, 'rebuke': 2086, 'guru': 1173, 'entrepreneur': 877, 'main': 1556, 'character': 439, 'letter': 1489, 'welfare': 2801, 'rarely': 2072, 'occasional': 1774, 'prasaht_': 1953, 'asset': 168, 'accede': 19, 'kerry': 1426, 'status_culture': 2429, 'besiege': 263, 'palma': 1825, 'mozambique': 1697, 'fare': 975, 'gape_slut_dream': 1091, 'gape': 1090, 'sixth': 2337, 'kes_sport': 1427, 'miraculously': 1658, 'cure': 637, 'command': 523, 'k_bell': 1416, 'hoard': 1226, 'pandora': 1828, 'silky': 2323, 'nutmeg': 1765, 'scarlet': 2234, 'envy': 881, 'recommend': 2092, 'highly': 1218, 'aftermath': 62, 'bombardment': 304, 'lene': 1484, 'heal': 1200, 'natanael_l': 1721, 'lemonade_inc': 1483, 'deny': 707, 'technically': 2535, '_jackson_graham': 4, 'irrational': 1377, 'fear': 983, 'someday': 2374, 'filippo': 1004, 'variety': 2738, 'spook': 2399, 'scandalous': 2231, 'bath': 240, 'didnt': 738, 'dr_sportello': 800, 'survival': 2505, 'trishu_gujju': 2654, 'photon__glrl': 1879, 'sushi_anwy': 2507, 'justicessr_': 1415, 'its_akki_': 1381, 'ayusmita__': 207, 'immortal_photon': 1279, 'pari_': 1837, 'suite': 2483, 'reposer': 2139, 'longue': 1527, 'linge': 1512, 'encore': 858, 'wreck': 2834, 'lube': 1538, 'platinum': 1905, 'silicon': 2322, 'resignation': 2150, 'amid': 105, 'flip': 1027, 'braider': 322, 'diamond': 734, 'rat': 2073, 'prevention': 1970, 'france_en': 1064, 'consequential': 556, 'election': 846, 'interference': 1361, 'resound': 2153, 'direct': 751, 'the_veenad': 2563, 'hindrance': 1221, 'colour': 514, 'clothe': 491, 'crazy_myself': 613, 'comfortable': 522, 'usual': 2724, 'typist': 2680, 'missy': 1662, 'consulate': 564, 'shin': 2301, 'continuando': 572, 'rare': 2071, 'intend': 1354, 'maim': 1555, 'sterility': 2435, 'cloud': 492, 'vertex': 2744, 'clash': 477, 'chang': 435, 'amazingly': 101, 'dinero': 748, 'aproko_doctor': 147, 'depend': 710, 'peek': 1855, 'biology': 276}\n",
            "(1690, 2853)\n"
          ]
        }
      ],
      "source": [
        "print(Tfidf_vect.vocabulary_)\n",
        "print(Train_X_Tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI2CwGXqKS7A"
      },
      "outputs": [],
      "source": [
        "#n-gram Tokenization\n",
        "import pickle\n",
        "tfidf_vect_ngram = None\n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=8000)\n",
        "tfidf_vect_ngram.fit(data['lemma_str'])\n",
        "Train_X_ngram =  tfidf_vect_ngram.transform(Train_X)\n",
        "Test_X_ngram =  tfidf_vect_ngram.transform(Test_X)\n",
        "\n",
        "with open('vectorizer1.pkl', 'wb') as fin:\n",
        "    pickle.dump(tfidf_vect_ngram, fin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "237EpgOQKe32",
        "outputId": "58828f6d-b50d-4eb1-9a61-bb866189d3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1690, 8000)\n",
            "  (0, 6854)\t0.31754291759188236\n",
            "  (0, 6853)\t0.31754291759188236\n",
            "  (0, 6849)\t0.25756580719971495\n",
            "  (0, 5680)\t0.31754291759188236\n",
            "  (0, 5679)\t0.2622625642595767\n",
            "  (0, 2473)\t0.22377866471860922\n",
            "  (0, 2318)\t0.23220489920954088\n",
            "  (0, 2046)\t0.6350858351837647\n",
            "  (0, 316)\t0.2346223875934239\n",
            "  (1, 5807)\t0.7385649015217742\n",
            "  (1, 5721)\t0.2871138990424329\n",
            "  (1, 2200)\t0.6099897500915761\n",
            "  (2, 6348)\t0.34078189906607054\n",
            "  (2, 6347)\t0.34078189906607054\n",
            "  (2, 4694)\t0.34078189906607054\n",
            "  (2, 4693)\t0.34078189906607054\n",
            "  (2, 4691)\t0.2871703508999439\n",
            "  (2, 1751)\t0.32343016316735335\n",
            "  (2, 1478)\t0.34078189906607054\n",
            "  (2, 1477)\t0.34078189906607054\n",
            "  (2, 1476)\t0.34078189906607054\n",
            "  (3, 7612)\t0.2782836569372748\n",
            "  (3, 7611)\t0.2782836569372748\n",
            "  (3, 7606)\t0.2540607597636237\n",
            "  (3, 7141)\t0.2782836569372748\n",
            "  :\t:\n",
            "  (1688, 5639)\t0.33983486410701597\n",
            "  (1688, 5638)\t0.33983486410701597\n",
            "  (1688, 5636)\t0.3225313487873301\n",
            "  (1688, 4840)\t0.3225313487873301\n",
            "  (1688, 2781)\t0.33983486410701597\n",
            "  (1688, 2774)\t0.267083512288147\n",
            "  (1688, 2473)\t0.23948823261880278\n",
            "  (1689, 7585)\t0.25130600493905975\n",
            "  (1689, 7584)\t0.25130600493905975\n",
            "  (1689, 7577)\t0.20075114616202902\n",
            "  (1689, 6861)\t0.2139110238950863\n",
            "  (1689, 6016)\t0.25130600493905975\n",
            "  (1689, 6015)\t0.25130600493905975\n",
            "  (1689, 6014)\t0.25130600493905975\n",
            "  (1689, 5870)\t0.25130600493905975\n",
            "  (1689, 5869)\t0.25130600493905975\n",
            "  (1689, 5721)\t0.11593253652237484\n",
            "  (1689, 3679)\t0.25130600493905975\n",
            "  (1689, 3678)\t0.25130600493905975\n",
            "  (1689, 3675)\t0.24189426038222442\n",
            "  (1689, 2394)\t0.2463052440742846\n",
            "  (1689, 2391)\t0.21199008609793532\n",
            "  (1689, 1829)\t0.25130600493905975\n",
            "  (1689, 1828)\t0.2463052440742846\n",
            "  (1689, 1824)\t0.21016289071886426\n"
          ]
        }
      ],
      "source": [
        "print(Train_X_ngram.shape)\n",
        "print(Train_X_ngram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atTXFyCCKoXp"
      },
      "outputs": [],
      "source": [
        "X_train = Train_X_ngram\n",
        "Y_train = Train_Y\n",
        "X_test = Test_X_ngram\n",
        "Y_test = Test_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_6DZPgAKx7k"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    svm.SVC(C=1.0, kernel='linear', degree=10, gamma='auto'),\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(),\n",
        "    LogisticRegression(random_state=0),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr0hog6qK6lJ"
      },
      "outputs": [],
      "source": [
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "entries = []\n",
        "y_preds=[]\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, X_train, Train_Y, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy*100))\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2lkDiDeLAHz",
        "outputId": "bb11c22e-ed3f-4230-c60a-9b86b5fe5f4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model_name\n",
              "LinearSVC                 73.372781\n",
              "LogisticRegression        71.420118\n",
              "MultinomialNB             69.881657\n",
              "RandomForestClassifier    57.041420\n",
              "SVC                       72.248521\n",
              "Name: accuracy, dtype: float64"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_df.groupby('model_name').accuracy.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2I0rqdOLIDC",
        "outputId": "48be26bc-010b-4974-89af-9562e2650a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                model_name  fold_idx   accuracy\n",
            "0                      SVC         0  70.414201\n",
            "1                      SVC         1  71.005917\n",
            "2                      SVC         2  76.331361\n",
            "3                      SVC         3  71.301775\n",
            "4                      SVC         4  72.189349\n",
            "5   RandomForestClassifier         0  57.692308\n",
            "6   RandomForestClassifier         1  56.804734\n",
            "7   RandomForestClassifier         2  56.508876\n",
            "8   RandomForestClassifier         3  56.213018\n",
            "9   RandomForestClassifier         4  57.988166\n",
            "10               LinearSVC         0  70.710059\n",
            "11               LinearSVC         1  72.189349\n",
            "12               LinearSVC         2  77.514793\n",
            "13               LinearSVC         3  73.964497\n",
            "14               LinearSVC         4  72.485207\n",
            "15           MultinomialNB         0  70.710059\n",
            "16           MultinomialNB         1  68.047337\n",
            "17           MultinomialNB         2  71.597633\n",
            "18           MultinomialNB         3  70.414201\n",
            "19           MultinomialNB         4  68.639053\n",
            "20      LogisticRegression         0  70.118343\n",
            "21      LogisticRegression         1  69.822485\n",
            "22      LogisticRegression         2  74.556213\n",
            "23      LogisticRegression         3  70.710059\n",
            "24      LogisticRegression         4  71.893491\n"
          ]
        }
      ],
      "source": [
        "print(cv_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ahlc1zhuLRwc"
      },
      "outputs": [],
      "source": [
        "lc =LinearSVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_RbG4QLi0N"
      },
      "outputs": [],
      "source": [
        "model =lc.fit(X_train,Train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8km0IpULlyw"
      },
      "outputs": [],
      "source": [
        "Y_pred =model.predict(Test_X_ngram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0d-vJtfOKgi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'classify_model_1.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb7GPHd7M6oV",
        "outputId": "71e71860-3c9f-4b93-8137-e2eb17229ad3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7565011820330969"
            ]
          },
          "execution_count": 53,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Test_Y,Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUiRLWQpQgaP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
